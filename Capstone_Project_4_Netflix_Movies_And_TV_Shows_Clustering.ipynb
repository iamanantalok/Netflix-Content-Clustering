{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamanantalok/Netflix-Content-Clustering/blob/main/Capstone_Project_4_Netflix_Movies_And_TV_Shows_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Netflix Movies and TV Shows Clustering**  \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**            - Anant Alok\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With over 83 million subscribers and a global presence spanning 190 countries, Netflix reigns as the world's foremost Internet television network. Daily, users consume more than 125 million hours of TV and film content, including original series, documentaries, and feature films. Netflix grants members the freedom to watch as much as they desire, at their convenience, on virtually any internet-connected screen. Members can pause, play, and resume without interruption or commitment.\n",
        "\n",
        "This dataset, compiled in 2019 from Flixable, a third-party Netflix search engine, encompasses Netflix's collection of TV shows and movies. Intriguingly, a 2018 report revealed that Netflix's TV show catalog has nearly tripled since 2010, while the number of movies has declined by over 2,000 titles during the same period. This dataset provides ample opportunity to uncover additional insights.\n",
        "\n",
        "In this project, our focus revolved around solving a text clustering challenge. Our goal was to categorize Netflix movies and shows into clusters based on similarity, ensuring that shows within a cluster shared common characteristics, while those in different clusters diverged.\n",
        "\n",
        "Our project encompassed the following tasks:\n",
        "\n",
        "1. **Exploratory Data Analysis (EDA):** We began by addressing missing data and conducting EDA.\n",
        "\n",
        "2. **Content Analysis by Country:** We sought to understand the types of content available in different countries.\n",
        "\n",
        "3. **Shift towards TV:** An examination of Netflix's focus on TV content versus movies in recent years.\n",
        "\n",
        "4. **Clustering by Text-Based Features:** We employed attributes like cast, country, genre, director, rating, and description for clustering. Utilizing TF-IDF vectorization, we tokenized, preprocessed, and vectorized these attributes.\n",
        "\n",
        "5. **Dimensionality Reduction:** To address dimensionality issues, we applied Principal Component Analysis (PCA).\n",
        "\n",
        "6. **Cluster Creation:** Using K-Means Clustering and Agglomerative Hierarchical Clustering, we constructed two distinct types of clusters. We determined the optimal number of clusters using methods such as the elbow method, silhouette score, and dendrogram analysis.\n",
        "\n",
        "7. **Content-Based Recommender System:** Leveraging cosine similarity on the similarity matrix, we developed a content-based recommender system. Users receive ten recommendations based on their viewing preferences.\n",
        "\n",
        "This comprehensive analysis and recommendation system aim to enhance user satisfaction and subsequently improve Netflix's retention rates."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix, the world's largest online streaming service provider, boasts a staggering 220 million subscribers as of Q2 2022. In order to retain subscribers and provide an improved user experience, it's crucial for Netflix to efficiently categorize the shows available on its platform. This categorization allows for a deeper understanding of show similarities and differences, which, in turn, can be used to offer personalized show recommendations tailored to individual preferences.\n",
        "\n",
        "The primary objective of this project is to group Netflix shows into clusters, ensuring that shows within the same cluster exhibit similarity while those in different clusters diverge significantly. This clustering endeavor aims to enhance the overall user experience and reduce subscriber churn."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Libraries\n",
        "import string\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "# Third-party Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import missingno as msno\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Disable warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_project = pd.read_csv('/content/drive/MyDrive/Capstone_Project_4-Netflix-Movies-and-shows-clustering/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')\n",
        "netflix_df = netflix_project.copy()"
      ],
      "metadata": {
        "id": "En1UH-c-k5oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the first five and last five rows of the Netflix dataset\n",
        "concatenated_df = pd.concat([netflix_df.head(), netflix_df.tail()])\n",
        "\n",
        "# Display the concatenated DataFrame\n",
        "print(concatenated_df)\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows and columns in the Netflix dataset\n",
        "print(f'Number of rows: {netflix_df.shape[0]}\\nNumber of columns: {netflix_df.shape[1]}')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about the Netflix dataset\n",
        "netflix_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the number of duplicate values in the Netflix dataset\n",
        "duplicate_value = len(netflix_df[netflix_df.duplicated()])\n",
        "print(\"The number of duplicate values in the dataset is =\", duplicate_value)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the count of null values in each column of the Netflix dataset\n",
        "print(\"-\" * 32)\n",
        "print(\"Null value count in each column:\")\n",
        "print(\"-\" * 32)\n",
        "null_count_by_column = netflix_df.isna().sum()\n",
        "print(null_count_by_column)\n",
        "print(\"-\" * 42)\n",
        "\n",
        "# Calculate and display the percentage of null values in each column\n",
        "print(\"Percentage of null values in each column:\")\n",
        "print(\"-\" * 42)\n",
        "percentage_null_by_column = (null_count_by_column / len(netflix_df)) * 100\n",
        "print(percentage_null_by_column)\n",
        "print(\"-\" * 42)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize missing values using the missingno library\n",
        "msno.bar(netflix_df, color='green', sort='ascending', figsize=(10, 3), fontsize=15)\n",
        "\n",
        "# Create a bar plot to show the count of missing values in each column\n",
        "plt.figure(figsize=(15, 8))\n",
        "plots = sns.barplot(x=netflix_df.columns, y=netflix_df.isna().sum())\n",
        "plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "# Annotate the bar plot with the count of missing values\n",
        "for bar in plots.patches:\n",
        "    plots.annotate(bar.get_height(),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=12, xytext=(0, 8),\n",
        "                   textcoords='offset points')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Netflix Movies and TV Shows Clustering\" dataset consists of 12 columns, with just one column containing integer data. Notably, there are no duplicate values present, but there are null values in five columns: director, cast, country, date_added, and rating.\n",
        "\n",
        "This dataset serves as a valuable resource for investigating trends in Netflix's extensive collection of movies and TV shows. Furthermore, it offers an opportunity to construct clustering models that group similar titles together based on common attributes like genre, country of origin, and rating."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the list of available columns in the Netflix dataset\n",
        "print(f\"Available columns:\\n{netflix_df.columns.to_list()}\")"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a summary of statistics for the Netflix dataset (including all columns)\n",
        "summary_stats = netflix_df.describe(include='all').T\n",
        "print(summary_stats)"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"**Netflix Movies and TV Shows Clustering**\" dataset contains the following variables:\n",
        "\n",
        "1. **show_id:** A unique identifier for each movie or TV show.\n",
        "2. **type:** Indicates whether the entry is a movie or a TV show.\n",
        "3. **title:** The name of the movie or TV show.\n",
        "4. **director:** The name(s) of the director(s) of the movie or TV show.\n",
        "5. **cast:** The names of the actors and actresses featured in the movie or TV show.\n",
        "6. **country:** The country or countries where the movie or TV show was produced.\n",
        "7. **date_added:** The date when the movie or TV show was added to Netflix.\n",
        "8. **release_year:** The year when the movie or TV show was originally released.\n",
        "9. **rating:** The TV rating or movie rating of the movie or TV show.\n",
        "10. **duration:** The length of the movie or TV show, either in minutes or seasons.\n",
        "11. **listed_in:** The categories or genres of the movie or TV show.\n",
        "12. **description:** A brief synopsis or summary of the movie or TV show."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check and print the number of unique values for each variable (column) in the Netflix dataset\n",
        "for column in netflix_df.columns.tolist():\n",
        "    unique_count = netflix_df[column].nunique()\n",
        "    print(f\"No. of unique values in {column} is {unique_count}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've narrowed down our focus to key columns: 'type', 'title', 'director', 'cast', 'country', 'rating', 'listed_in', and 'description'.\n",
        "\n",
        "Here's what's on the horizon:\n",
        "\n",
        "1. **Clustering:** I'll create a 'cluster' column using K-means and Hierarchical clustering methods to group similar data points.\n",
        "\n",
        "2. **Recommendations:** We're developing a personalized content-based recommendation system that considers user preferences and viewing history.\n",
        "\n",
        "This strategy is all about insights and user satisfaction."
      ],
      "metadata": {
        "id": "PqqRU48PoGYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Missing Data in Each Feature"
      ],
      "metadata": {
        "id": "6HME2dW3on8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the count of null values in each column of the Netflix dataset\n",
        "print(\"-\" * 32)\n",
        "print(\"Null value count in each column:\")\n",
        "print(\"-\" * 32)\n",
        "null_count_by_column = netflix_df.isna().sum()\n",
        "print(null_count_by_column)\n",
        "print(\"-\" * 42)\n",
        "\n",
        "# Calculate and display the percentage of null values in each column\n",
        "print(\"Percentage of null values in each column:\")\n",
        "print(\"-\" * 42)\n",
        "percentage_null_by_column = (null_count_by_column / len(netflix_df)) * 100\n",
        "print(percentage_null_by_column)\n",
        "print(\"-\" * 42)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each unique value in the \"date_added\" column\n",
        "date_added_counts = netflix_df[\"date_added\"].value_counts()\n",
        "print(date_added_counts)"
      ],
      "metadata": {
        "id": "vBe-FWt-o9_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each unique value in the \"rating\" column\n",
        "rating_counts = netflix_df['rating'].value_counts()\n",
        "print(rating_counts)"
      ],
      "metadata": {
        "id": "OGuHCTABpEjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each unique value in the \"country\" column\n",
        "country_counts = netflix_df['country'].value_counts()\n",
        "print(country_counts)"
      ],
      "metadata": {
        "id": "b4CWN8zapG5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Considering the low percentage of null values in 'date_added' and 'rating,' it's advisable to exclude those data points to maintain the impartiality of our clustering model.\n",
        "\n",
        "-  For 'director' and 'cast,' where null values are relatively high and we lack information about the actual movies or TV shows, it's prudent to replace these entries with 'unknown.'\n",
        "\n",
        "-  Regarding 'country,' since only 6% of the values are missing, and the majority of movies/shows originate from the US, we can fill the null values with the mode."
      ],
      "metadata": {
        "id": "3fQvkb9spVy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute 'director' and 'cast' columns with \"Unknown\" for missing values\n",
        "netflix_df[['director', 'cast']] = netflix_df[['director', 'cast']].fillna(\"Unknown\")\n",
        "\n",
        "# Impute missing values in the 'country' column with the mode (most common country)\n",
        "netflix_df['country'] = netflix_df['country'].fillna(netflix_df['country'].mode()[0])\n",
        "\n",
        "# Drop rows with missing values in 'date_added' and 'rating' columns\n",
        "netflix_df.dropna(subset=['date_added', 'rating'], inplace=True)\n"
      ],
      "metadata": {
        "id": "4jP5kpnVpl3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the count of null values in each column after imputation\n",
        "print(\"-\" * 50)\n",
        "print(\"Null value count in each column after imputation:\")\n",
        "print(\"-\" * 50)\n",
        "null_count_by_column = netflix_df.isna().sum()\n",
        "print(null_count_by_column)\n",
        "print(\"-\" * 59)\n",
        "\n",
        "# Calculate and display the percentage of null values in each column after imputation\n",
        "print(\"Percentage of null values in each column after imputation:\")\n",
        "print(\"-\" * 59)\n",
        "percentage_null_by_column = (null_count_by_column / len(netflix_df)) * 100\n",
        "print(percentage_null_by_column)\n",
        "print(\"-\" * 59)\n"
      ],
      "metadata": {
        "id": "n0lC16BCpurb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Country and Listed_in :*"
      ],
      "metadata": {
        "id": "3N6K7Q-dqENn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count and display the number of movies/TV shows per country\n",
        "print(\"Top countries by the number of movies/TV shows:\")\n",
        "print('-'*47)\n",
        "country_counts = netflix_df['country'].value_counts()\n",
        "print(country_counts)\n",
        "\n",
        "# Count and display the number of movies/TV shows per genre\n",
        "print(\"\\nGenres of shows:\")\n",
        "print('-'*16)\n",
        "genre_counts = netflix_df['listed_in'].value_counts()\n",
        "print(genre_counts)\n",
        "\n",
        "# Find entries with multiple countries listed\n",
        "multiple_countries = netflix_df[netflix_df['country'].str.contains(',', na=False)]\n",
        "\n",
        "# Find entries with multiple genres listed\n",
        "multiple_genres = netflix_df[netflix_df['listed_in'].str.contains(',', na=False)]\n",
        "\n",
        "# Print movies/TV shows with multiple countries listed\n",
        "print(\"\\nMovies/TV Shows Filmed in Multiple Countries:\")\n",
        "print('-'*45)\n",
        "print(multiple_countries[['title', 'country']])\n",
        "\n",
        "# Print movies/TV shows with multiple genres listed\n",
        "print(\"\\nMovies/TV Shows with Multiple Genres:\")\n",
        "print('-'*36)\n",
        "print(multiple_genres[['title', 'listed_in']])\n"
      ],
      "metadata": {
        "id": "nHMsSi_oqiot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To streamline the analysis, let's focus solely on the primary filming location of each movie or TV show and the primary genre."
      ],
      "metadata": {
        "id": "lM0PUG4grYeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract the primary value (first value in a comma-separated list)\n",
        "def extract_primary(value):\n",
        "    if isinstance(value, str):\n",
        "        return value.split(',')[0]\n",
        "    return value\n",
        "\n",
        "# Apply the function to 'country' and 'listed_in' columns to consider only the primary values\n",
        "netflix_df['country'] = netflix_df['country'].apply(extract_primary)\n",
        "netflix_df['listed_in'] = netflix_df['listed_in'].apply(extract_primary)\n",
        "\n",
        "# Print the DataFrame with simplified values\n",
        "netflix_df"
      ],
      "metadata": {
        "id": "MrSo6h3crcsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Data Handling for date_added Column :*"
      ],
      "metadata": {
        "id": "W9xd_x0rrujW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Typecast 'date_added' from string to datetime\n",
        "netflix_df[\"date_added\"] = pd.to_datetime(netflix_df['date_added'])\n",
        "\n",
        "# Find the first and last date on which a show was added on Netflix\n",
        "min_date_added = netflix_df.date_added.min().strftime('%Y-%m-%d')\n",
        "max_date_added = netflix_df.date_added.max().strftime('%Y-%m-%d')\n",
        "\n",
        "# Print the range of dates when shows were added on Netflix\n",
        "print(f\"The shows were added on Netflix between {min_date_added} and {max_date_added}.\")\n",
        "\n",
        "# Adding new attributes for day, month, and year of date added\n",
        "netflix_df['day_added'] = netflix_df['date_added'].dt.day\n",
        "netflix_df['month_added'] = netflix_df['date_added'].dt.month\n",
        "netflix_df['year_added'] = netflix_df['date_added'].dt.year\n",
        "\n",
        "# Dropping the original 'date_added' column\n",
        "netflix_df.drop('date_added', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "k9e96U2Er-8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Transforming Ratings into Age-Based Content Restrictions :*"
      ],
      "metadata": {
        "id": "JdIrL4Hksji6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a countplot to visualize the age ratings for shows on Netflix\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(x='rating', data=netflix_df)\n",
        "\n",
        "# Provide an observation as text on the graph\n",
        "plt.title(\"Age Ratings for Shows on Netflix\")\n",
        "plt.xlabel(\"Age Rating\")\n",
        "plt.ylabel(\"Number of Shows\")\n",
        "\n",
        "# Calculate the count for the most frequent rating\n",
        "most_common_rating = netflix_df['rating'].mode()[0]\n",
        "count_most_common_rating = (netflix_df['rating'] == most_common_rating).sum()\n",
        "\n",
        "# Add the observation as text on the graph\n",
        "plt.text(0.5, count_most_common_rating + 10, f\"Most Common Rating: {most_common_rating}\", ha='center', fontsize=8)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "kS04wiN9s2PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the unique age ratings in the 'rating' column before mapping\n",
        "unique_ratings_before = netflix_df.rating.unique()\n",
        "print(\"Unique ratings before mapping:\", unique_ratings_before)\n",
        "\n",
        "# Define a mapping to change the values in the 'rating' column\n",
        "rating_map = {\n",
        "    'TV-MA': 'Adults',\n",
        "    'R': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-14': 'Young Adults',\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'NR': 'Adults',\n",
        "    'TV-G': 'Kids',\n",
        "    'TV-Y': 'Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'NC-17': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'UR': 'Adults'\n",
        "}\n",
        "\n",
        "# Replace the values in the 'rating' column using the mapping\n",
        "netflix_df['rating'].replace(rating_map, inplace=True)\n",
        "\n",
        "# Display the unique age ratings in the 'rating' column after mapping\n",
        "unique_ratings_after = netflix_df['rating'].unique()\n",
        "print(\"Unique ratings after mapping:\", unique_ratings_after)\n",
        "\n",
        "# Create a countplot to visualize the new age ratings for shows on Netflix\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(x='rating', data=netflix_df)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n4UMnUMmtzEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Around 50% of shows on Netflix are produced for adult audience, followed by young adults, older kids, and kids. Netflix has the least number of shows specifically produced for teenagers compared to other age groups.**"
      ],
      "metadata": {
        "id": "hfLSPW2_uaia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Preparing Duration Data :*"
      ],
      "metadata": {
        "id": "fQOw74guuo6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the 'duration' column and change its datatype to integer\n",
        "netflix_df['duration'] = netflix_df['duration'].apply(lambda x: int(x.split()[0]))\n",
        "\n",
        "# Print the number of seasons for TV shows\n",
        "tv_show_season_counts = netflix_df[netflix_df['type'] == 'TV Show']['duration'].value_counts()\n",
        "print(\"Number of seasons for TV shows:\")\n",
        "print(tv_show_season_counts)\n",
        "\n",
        "# Print the unique movie lengths in minutes\n",
        "unique_movie_lengths = netflix_df[netflix_df['type'] == 'Movie']['duration'].unique()\n",
        "print(\"Unique movie lengths in minutes:\")\n",
        "print(unique_movie_lengths)\n",
        "\n",
        "# Check the datatype of the 'duration' column\n",
        "duration_datatype = netflix_df['duration'].dtype\n",
        "print(\"Datatype of duration:\", duration_datatype)\n"
      ],
      "metadata": {
        "id": "iak4hZwVurlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 12 attributes, some with improper data types like 'date_added' and 'duration,' which we convert to the desired data types. After this conversion, we discover that there are more movies than TV shows in the 'type' feature. We create a word cloud image to identify common words in titles.\n",
        "\n",
        "For movies and TV shows filmed in multiple countries and with multiple genres, we focus only on the primary country and genre. The majority of shows on Netflix are rated TV-MA, followed by TV-14 and TV-PG. We adjust ratings to cater to different viewer preferences, such as adults, teens, and older kids.\n",
        "\n",
        "Approximately 50% of Netflix shows target adult audiences, followed by young adults, older kids, and kids. Netflix has fewer shows specifically produced for teenagers compared to other age groups."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Examining the Content Variety on Netflix**"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 1x2 subplots with a specified figure size\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Countplot to show the count of 'type' values (Movies and TV Shows)\n",
        "countplot_graph = sns.countplot(x='type', data=netflix_df, ax=ax[0])\n",
        "countplot_graph.set_title('Count of Values', size=20)\n",
        "\n",
        "# Pie chart to show the percentage distribution of 'type'\n",
        "netflix_df['type'].value_counts().plot(kind='pie', autopct='%1.2f%%', ax=ax[1], figsize=(15, 6), startangle=90)\n",
        "plt.title('Percentage Distribution', size=20)\n",
        "\n",
        "# Ensure tight layout for better visualization\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the combined visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selection of a countplot for displaying the precise counts of \"Movies\" and \"TV Shows\" offers a straightforward comparison of the content types within our dataset. Furthermore, we have opted for a pie chart to illustrate the percentage distribution of these content categories, providing insight into the proportion of movies and TV shows in the entire dataset."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Movies\" dominate Netflix's content offerings, while \"TV Shows\" represent a smaller share. The pie chart visually emphasizes this distribution, highlighting the significant presence of \"Movies\" in the overall content.\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Content Strategy: The data suggests a significant prevalence of \"Movies\" in Netflix's content, which can guide content acquisition and production strategies. Focusing on acquiring diverse and popular movie titles can broaden Netflix's appeal.\n",
        "\n",
        "User Engagement: Recognizing the dominance of \"Movies\" allows for tailored marketing and engagement efforts. Targeted promotional campaigns for specific movie genres can attract and retain subscribers effectively.\n",
        "\n",
        "Retention Strategies: Customized recommendations and curated collections centered around movies can enhance user satisfaction and prolong subscription durations.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "While the visualizations don't directly indicate negative growth, the limited presence of \"TV Shows\" may present challenges:\n",
        "\n",
        "Content Diversity: Potential dissatisfaction among subscribers who prefer TV series due to the scarcity or variety of available content.\n",
        "\n",
        "Market Competition: Competition from platforms with a broader TV show selection may affect Netflix's market share.\n",
        "\n",
        "Subscription Tier Adjustment: To align with user preferences, Netflix may need to optimize its subscription tiers, potentially impacting perceived value."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Leading Nations in Content Production**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping and aggregating the data to get the top 10 countries with the most unique titles\n",
        "df_country = netflix_df.groupby(['country']).agg({'title': 'nunique'}).reset_index().sort_values(by=['title'], ascending=False)[:10]\n",
        "\n",
        "# Create a bar chart to show the top 10 countries for content creation\n",
        "plt.figure(figsize=(15, 6))\n",
        "barplot = sns.barplot(y=\"country\", x='title', data=df_country)\n",
        "plt.xticks(rotation=60)\n",
        "plt.title('Top 10 Countries for Content Creation on Netflix')\n",
        "plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "# Show the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar plot is a fitting choice for visualizing the distribution of primary filming countries in Netflix content due to its suitability for categorical data. Each country is represented by a bar, enabling easy comparisons of show counts. Bars can be arranged in descending order to highlight top-contributing countries. The y-axis values (show counts) are easily interpreted, and bar lengths reveal countries with a significant presence in Netflix content production. In summary, a bar plot is effective for presenting this categorical data, simplifying comparisons, and extracting insights concisely.\n"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The list of top countries with the most shows on Netflix provides valuable insights into the content distribution based on primary filming locations:\n",
        "\n",
        "1. **Content Production Leaders**: The United States leads with the highest number of shows, signifying its significant contribution to Netflix's content library, likely due to its robust entertainment industry.\n",
        "\n",
        "2. **Global Diversity**: Countries like India, the United Kingdom, Canada, and Japan also have substantial show counts, reflecting a diverse range of content from around the world, catering to various viewer preferences and cultures.\n",
        "\n",
        "3. **Language and Localization**: The presence of shows from different countries demonstrates Netflix's commitment to offering content in multiple languages and localizing it for global audiences, attracting a broader subscriber base.\n",
        "\n",
        "4. **Regional Appeal**: South Korea, Spain, and Mexico are notable contributors, indicating the popularity of content from these regions and a growing interest in international shows.\n",
        "\n",
        "5. **Audience Segmentation**: The country-wise distribution helps Netflix tailor content for specific regions, catering to local tastes and preferences.\n",
        "\n",
        "6. **Collaborative Productions**: Co-productions between countries contribute to higher numbers, fostering diversity and engaging content through resource and talent sharing.\n",
        "\n",
        "7. **Market Penetration**: The number of shows from a country may reflect Netflix's market presence, with higher numbers indicating a stronger focus in certain regions."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "1. **Global Market Expansion**: Diverse content attracts a global audience, expanding Netflix's subscriber base.\n",
        "\n",
        "2. **Localized Content**: Tailoring content for top countries boosts engagement and satisfaction.\n",
        "\n",
        "3. **Cultural Relevance**: Catering to cultural preferences fosters inclusivity and connection.\n",
        "\n",
        "4. **Strategic Partnerships**: Successful collaborations strengthen Netflix's market position.\n",
        "\n",
        "5. **Data-Informed Decisions**: Insights optimize content strategy and resource allocation.\n",
        "\n",
        "Potential Challenges and Negative Impact:\n",
        "\n",
        "1. **Market Saturation**: Overreliance on content from a few countries can limit global appeal.\n",
        "\n",
        "2. **Cultural Misalignment**: Inaccurate adaptation risks backlash and attrition.\n",
        "\n",
        "3. **Competition and Differentiation**: Lack of diversity may hinder differentiation from competitors.\n",
        "\n",
        "4. **Localization Complexity**: Managing content for multiple countries strains budgets and efficiency.\n",
        "\n",
        "5. **Content Diversity**: Focusing on high-show-count countries can overlook smaller contributors."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Content Development Across Years**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data by type (TV Show or Movie)\n",
        "tv_show = netflix_df[netflix_df[\"type\"] == \"TV Show\"]\n",
        "movie = netflix_df[netflix_df[\"type\"] == \"Movie\"]\n",
        "\n",
        "col = \"year_added\"\n",
        "\n",
        "# Count content added each year for TV Shows and Movies\n",
        "content_1 = tv_show[col].value_counts().reset_index()\n",
        "content_1 = content_1.rename(columns={col: \"count\", \"index\": col})\n",
        "content_1 = content_1.sort_values(col)\n",
        "\n",
        "content_2 = movie[col].value_counts().reset_index()\n",
        "content_2 = content_2.rename(columns={col: \"count\", \"index\": col})\n",
        "content_2 = content_2.sort_values(col)\n",
        "\n",
        "# Create traces for TV Shows and Movies\n",
        "trace1 = go.Scatter(x=content_1[col], y=content_1[\"count\"], name=\"TV Shows\", marker=dict(color=\"#db0000\"))\n",
        "trace2 = go.Scatter(x=content_2[col], y=content_2[\"count\"], name=\"Movies\", marker=dict(color=\"#564d4d\"))\n",
        "\n",
        "data = [trace1, trace2]\n",
        "layout = go.Layout(\n",
        "    title=\"Content Added Over the Years\",\n",
        "    xaxis=dict(title=\"Year\"),\n",
        "    yaxis=dict(title=\"Count\"),\n",
        "    legend=dict(x=0.4, y=1.1, orientation=\"h\")\n",
        ")\n",
        "fig = go.Figure(data, layout=layout)\n",
        "\n",
        "# Display the figure using Plotly\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selection of a line chart (specifically, a scatter plot with connected lines) in the provided code is appropriate for visualizing the growth of content (TV shows and movies) over the years."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TV Shows:\n",
        "\n",
        "- Limited TV show content was added in the early years (2008-2010), possibly signaling the onset of Netflix's original content creation.\n",
        "- Substantial TV show growth began around 2015, steadily increasing in subsequent years.\n",
        "- The peak TV show content growth occurred from 2016 to 2020, with 2020 reaching 697 additions.\n",
        "- A significant decline in TV show additions was noted in 2021 compared to prior years.\n",
        "\n",
        "Movies:\n",
        "\n",
        "- Like TV shows, the early years (2008-2010) had relatively few movie additions.\n",
        "- Movie additions increased notably from 2014, with a significant rise in 2016.\n",
        "- The growth continued from 2016 to 2019, peaking at 1497 additions in 2019.\n",
        "- A minor dip occurred in movie additions in 2020, followed by a relatively higher number in 2021.\n",
        "\n",
        "Overall Insights:\n",
        "\n",
        "- Both TV shows and movies experienced growth, notably from around 2015-2016.\n",
        "- The active years for content additions were 2018 and 2019 for both categories.\n",
        "- The drop in 2020 additions may be attributed to COVID-19-related production delays.\n",
        "- The lower 2021 additions for both TV shows and movies could signify a shift in strategy or ongoing external factors."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "1. **Strategic Decision-Making**: Insights into growth years (e.g., 2018-2019) inform successful strategies, aiding future decision-making.\n",
        "\n",
        "2. **Content Investment**: Recognizing growth trends allows resource allocation, focusing on popular content types like TV shows.\n",
        "\n",
        "3. **Subscriber Retention and Attraction**: Consistent growth attracts and retains subscribers, reducing churn rates.\n",
        "\n",
        "4. **Global Events Impact**: Understanding the pandemic's effect on 2020 content additions helps manage expectations during external disruptions.\n",
        "\n",
        "Potential Negative Impact:\n",
        "\n",
        "1. **Decline in Content Additions**: A drop in 2021 could lead to reduced subscriber engagement and satisfaction.\n",
        "\n",
        "2. **Competition and Variety**: Overgrowth without maintaining content quality and variety might overwhelm users, impacting engagement.\n",
        "\n",
        "3. **Production Delays**: Delays due to unforeseen events (e.g., pandemic) can reduce content availability, affecting user satisfaction.\n",
        "\n",
        "4. **Content Quality**: Maintaining high-quality content alongside growth is crucial to avoid subscriber dissatisfaction. Quantity should not compromise quality."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Busiest Month for Netflix Content Releases**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to store month values and counts of content added\n",
        "months_df = pd.DataFrame(netflix_df.month_added.value_counts())\n",
        "months_df.reset_index(inplace=True)\n",
        "months_df.rename(columns={'index': 'month', 'month_added': 'count'}, inplace=True)\n",
        "\n",
        "# Create a bar chart using Plotly\n",
        "fig = px.bar(months_df, x=\"month\", y=\"count\", text_auto=True, color='count', color_continuous_scale=['#db0000', '#564d4d'])\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': 'Month-wise Addition of Movies and Shows to the Platform',\n",
        "        'y': 0.95,\n",
        "        'x': 0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'},\n",
        "    autosize=False,\n",
        "    width=1000,\n",
        "    height=500)\n",
        "\n",
        "# Show the figure using Plotly\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is the ideal choice for visualizing this data because it efficiently presents the distribution of content additions across months, enabling straightforward comparison and interpretation of the information."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High-Volume Months: December (833), October (785), and January (757) are the busiest months for content additions on Netflix, indicating a spike in new content during these periods.\n",
        "\n",
        "End-of-Year Peaks: December's prominence as the top month aligns with the holiday season, catering to increased streaming activity and diverse content preferences during this festive period.\n",
        "\n",
        "Release Patterns: The top months for content additions may correspond to strategic release timings, taking advantage of holidays, school breaks, or cultural events to attract viewers.\n",
        "\n",
        "Mid-Year Dips: May (543) and June (542) exhibit lower content additions, likely due to factors such as production schedules, vacation seasons, or a focus on promoting existing content.\n",
        "\n",
        "Consistent Activity: Months from March to August (542 to 669) maintain a steady pace of content additions, ensuring a continuous flow of new material throughout the year.\n",
        "\n",
        "Potential Seasonal Patterns: The clustering of December, October, and January suggests potential seasonal patterns influenced by holidays, changing weather, or viewer behavior.\n",
        "\n",
        "Varied Peaks: Besides the top months, November (738) and February (472) also experience significant content additions, reflecting a diverse release strategy."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "1. **Strategic Content Releases**: Insights into peak months (e.g., December, October, January) inform strategic content releases, maximizing viewer engagement and subscription growth.\n",
        "\n",
        "2. **Subscriber Engagement**: Releasing content during high-engagement months enhances user satisfaction and prolongs subscriptions, improving business outcomes.\n",
        "\n",
        "3. **Marketing Campaigns**: High-content addition months can be targeted for effective marketing campaigns, attracting new and retaining existing subscribers.\n",
        "\n",
        "4. **Revenue Generation**: Optimizing content release schedules leads to increased user engagement and revenue through subscription growth and retention.\n",
        "\n",
        "Potential Negative Impact:\n",
        "\n",
        "1. **Content Oversaturation**: Overemphasizing high-volume months may lead to content oversaturation, potentially overwhelming users and hindering content engagement.\n",
        "\n",
        "2. **Neglecting Low-Volume Months**: Focusing too much on peak months might neglect low-volume months, risking dissatisfaction among users with fewer new content options.\n",
        "\n",
        "3. **Unpredictable Viewer Behavior**: While trends are evident, viewer behavior can be unpredictable, requiring flexibility in content release strategies.\n",
        "\n",
        "4. **Competition**: Competition for viewer attention during peak months may fragment the audience, potentially affecting subscription numbers.\n",
        "\n",
        "5. **Quality Over Quantity**: Prioritizing content quantity during high-volume months should not compromise quality, as maintaining viewer satisfaction and loyalty is paramount."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Dominant Days for Netflix Content Releases**"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to store day values and counts of content added\n",
        "days_df = pd.DataFrame(netflix_df.day_added.value_counts())\n",
        "days_df.reset_index(inplace=True)\n",
        "days_df.rename(columns={'index': 'day', 'day_added': 'count'}, inplace=True)\n",
        "\n",
        "# Create a bar chart using Plotly\n",
        "fig = px.bar(days_df, x=\"day\", y=\"count\", text_auto=True, color='count', color_continuous_scale=['#db0000', '#564d4d'])\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': 'Prominent Days for Content Additions',\n",
        "        'y': 0.95,\n",
        "        'x': 0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'},\n",
        "    autosize=False,\n",
        "    width=1200,\n",
        "    height=600)\n",
        "\n",
        "# Show the figure using Plotly\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is the ideal choice for visualizing this data because it efficiently presents the distribution of content additions across days of the week, enabling straightforward comparison and interpretation of the information."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weekdays Dominate: Weekdays (days 1 to 5) exhibit significantly higher content additions compared to weekends (days 6 and 7), indicating a preference for adding content during weekdays.\n",
        "\n",
        "Day 1 Peak: The first day of the month (day 1) boasts the highest content additions (2069), potentially indicating a trend of starting the month with new content.\n",
        "\n",
        "Mid-Month Peaks: Days around the 15th of the month (days 15 and 16) witness relatively high content additions (644 and 240, respectively), hinting at a mid-month content addition trend.\n",
        "\n",
        "End-of-Month Surges: Content additions spike toward the end of the month (days 31, 30, and 31), likely associated with content releases before month-end.\n",
        "\n",
        "Variation on Weekends: Days 6 and 7 (Saturday and Sunday) record lower content additions (165 and 162, respectively), suggesting a strategy of reduced focus on weekends.\n",
        "\n",
        "Consistency in Numbers: Days in the mid-range (days 18 to 28) maintain consistent content additions, indicating a steady flow of new content throughout the month.\n",
        "\n",
        "Influence of Viewer Behavior: Higher content additions at the beginning and middle of the month might reflect viewer behavior patterns, such as increased engagement after weekends and around mid-month paydays."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "1. **Strategic Content Releases**: Insights into high-content addition days (e.g., Mondays, mid-month, end-of-month) inform strategic content releases, maximizing viewer engagement and subscriptions.\n",
        "\n",
        "2. **Optimized User Engagement**: Aligning content releases with peak engagement days (e.g., weekdays) enhances user engagement and extends subscription durations.\n",
        "\n",
        "3. **Viewer Satisfaction**: Consistent content additions throughout the week boost viewer satisfaction, preventing content gaps and retaining user interest.\n",
        "\n",
        "4. **Content Variety**: Lower addition days (e.g., weekends) offer opportunities to diversify content and cater to different viewer preferences during those times.\n",
        "\n",
        "Potential Negative Impact:\n",
        "\n",
        "1. **Neglecting Weekends**: Focusing heavily on weekdays might neglect weekends, potentially leading to dissatisfaction among users who seek content during leisure days.\n",
        "\n",
        "2. **Viewer Fatigue**: Concentrating content additions on specific days might overwhelm viewers and result in oversaturation, reducing engagement.\n",
        "\n",
        "3. **Content Quality Over Quantity**: Prioritizing specific days for content additions should not compromise content quality, as maintaining viewer satisfaction is crucial.\n",
        "\n",
        "4. **Neglecting Viewer Diversity**: Viewer behavior varies, and exclusive reliance on insights from specific days might overlook users with different preferences and schedules.\n",
        "\n",
        "5. **Competition**: Similar patterns of concentrated content releases by other platforms could increase competition for viewer attention, possibly fragmenting the audience."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Genre Rankings: Top and Bottom 10**"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the 'listed_in' column to extract genres for analysis\n",
        "genres = netflix_df['listed_in'].str.split(', ', expand=True).stack()\n",
        "\n",
        "# Count the occurrences of each genre\n",
        "genres = genres.value_counts().reset_index().rename(columns={'index': 'genre', 0: 'count'})\n",
        "\n",
        "# Create subplots for top 10 and last 10 genres\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Top 10 genres\n",
        "top = sns.barplot(x='genre', y='count', data=genres[:10], ax=ax[0])\n",
        "top.set_title('Top 10 Genres on Netflix', size=20)\n",
        "plt.setp(top.get_xticklabels(), rotation=90)\n",
        "\n",
        "# Last 10 genres\n",
        "bottom = sns.barplot(x='genre', y='count', data=genres[-10:], ax=ax[1])\n",
        "bottom.set_title('Last 10 Genres on Netflix', size=20)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Ensure tight layout for better visualization\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the charts\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot is apt for visualizing genre distribution in the \"listed_in\" column due to its suitability for categorical data comparison."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 Genres:\n",
        "\n",
        "1. Diverse Genre Offerings: The top genres span dramas, comedies, documentaries, and action & adventure, reflecting Netflix's diverse content efforts.\n",
        "\n",
        "2. Mainstream Appeal: Popular genres like dramas, comedies, and documentaries indicate broad viewer appeal.\n",
        "\n",
        "3. Global Audience: \"International TV Shows\" suggests a focus on global content diversity.\n",
        "\n",
        "4. Family and Kids' Content: Inclusion of \"Children & Family Movies,\" \"Kids' TV,\" and \"Animation\" caters to family audiences.\n",
        "\n",
        "5. Entertainment Variety: \"Stand-Up Comedy\" and \"Music & Musicals\" diversify entertainment choices.\n",
        "\n",
        "Last 10 Genres:\n",
        "\n",
        "1. Niche and Specialized Content: \"Cult Movies,\" \"TV Horror,\" and \"Sci-Fi & Fantasy\" cater to specialized audiences.\n",
        "\n",
        "2. Limited Appeal: Genres like \"LGBTQ Movies,\" \"Sports Movies,\" and \"Spanish-Language TV Shows\" may have niche appeal.\n",
        "\n",
        "3. Highly Specific Content: \"TV Sci-Fi & Fantasy\" and \"TV Horror\" target specific genre enthusiasts.\n",
        "\n",
        "4. Limited Availability: Some genres (e.g., \"Sports Movies\") indicate limited content offerings.\n",
        "\n",
        "5. Viewer Diversity: \"TV Shows\" and \"Romantic Movies\" serve diverse interests despite lower counts.\n",
        "\n",
        "6. Content Focus: Lower counts in certain genres suggest resource allocation toward more mainstream options."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "1. **Viewer Engagement**: Offering diverse, popular genres can boost viewer engagement, longer viewing sessions, and subscription renewals.\n",
        "\n",
        "2. **Global Audience**: Inclusion of \"International TV Shows\" can expand Netflix's global audience, increasing international subscriptions and positive business impact.\n",
        "\n",
        "3. **Family-Friendly Content**: Genres like \"Children & Family Movies\" and \"Kids' TV\" attract families, driving subscriptions and positive word-of-mouth recommendations.\n",
        "\n",
        "4. **Entertainment Variety**: A mix of genres, including \"Stand-Up Comedy\" and \"Music & Musicals,\" appeals to diverse entertainment seekers, extending engagement.\n",
        "\n",
        "5. **Niche Audience Catering**: Lower-count genres may satisfy niche audiences with passionate fan bases, fostering loyalty and positive reviews.\n",
        "\n",
        "Potential Negative Impact:\n",
        "\n",
        "1. **Neglected Genres**: Overemphasizing popular genres may neglect those with lower counts, potentially decreasing engagement from viewers who prefer these genres.\n",
        "\n",
        "2. **Oversaturation**: Focusing heavily on popular genres might lead to oversaturation, overwhelming viewers with content choices and reducing engagement.\n",
        "\n",
        "3. **Limited Niche Content**: Prioritizing niche genres exclusively could limit viewership and result in negative growth if niche genres lack a sustainable audience.\n",
        "\n",
        "4. **Quality Over Quantity**: Prioritizing quantity over quality in specific genres may lead to viewer dissatisfaction, negative reviews, and potential churn.\n",
        "\n",
        "5. **Missed Opportunities**: Neglecting certain genres (e.g., LGBTQ Movies, Spanish-Language TV Shows) may miss opportunities to capture specific viewer segments, potentially leading to negative growth within those segments.\n",
        "\n",
        "6. **Competition**: Neglecting or not curating genres well might drive viewers to competing platforms with more diverse and tailored genre options."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Netflix's Yearly Content Influx: Shows and Movies**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size using Seaborn\n",
        "sns.set(rc={'figure.figsize': (15, 7)})\n",
        "\n",
        "# Create a countplot to visualize the total shows/movies added each year\n",
        "sns.countplot(x='year_added', data=netflix_df, palette=\"Set1\")\n",
        "\n",
        "# Set the title and formatting for the plot\n",
        "plt.title('Total Shows/Movies Added Each Year on Netflix', size='15', fontweight=\"bold\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is an appropriate choice for visualizing the distribution of shows and movies added to Netflix each year. It effectively displays the frequency of content additions for each year, facilitating straightforward comparison and data interpretation."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rapid Growth: Netflix experienced substantial content growth in recent years, with 2019 and 2020 as peak years, adding 2153 and 2009 shows/movies, respectively.\n",
        "\n",
        "Consistent Expansion: The trend continued with 1685 additions in 2018, indicating steady growth efforts.\n",
        "\n",
        "Steady Growth: In 2017 and 2016, Netflix added 1225 and 443 shows/movies, respectively, reflecting consistent content library growth.\n",
        "\n",
        "Recent Decline: There was a noticeable drop to 117 additions in 2021, but it's important to consider potential data incompleteness and evolving trends.\n",
        "\n",
        "Early Years: Content additions were lower in 2014 and earlier, reflecting Netflix's smaller content library during its early years."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Impact:**\n",
        "\n",
        "1. **Content Growth**: Recent years (2019, 2020) saw rapid content growth, attracting and retaining subscribers.\n",
        "\n",
        "2. **Subscriber Retention**: Consistent additions in 2017 and 2018 enhance subscriber satisfaction and loyalty.\n",
        "\n",
        "3. **Competitive Edge**: Regular updates make Netflix competitive by offering diverse content.\n",
        "\n",
        "4. **Market Expansion**: High additions show Netflix's global market expansion efforts.\n",
        "\n",
        "5. **Original Strategy**: Content growth aligns with Netflix's original content strategy.\n",
        "\n",
        "**Potential Negative Impact:**\n",
        "\n",
        "1. **Quality Concerns**: 2021's drop may indicate content quality issues, risking viewer dissatisfaction.\n",
        "\n",
        "2. **Subscription Risks**: Reduced additions could lead to subscriber attrition and less new sign-ups.\n",
        "\n",
        "3. **Saturation**: Oversaturation can overwhelm viewers, reducing engagement.\n",
        "\n",
        "4. **Missed Opportunities**: Lower early-year additions might have missed subscriber base growth.\n",
        "\n",
        "5. **Competition**: Reduced growth increases competition for viewer attention.\n",
        "\n",
        "6. **Staleness**: Fewer additions might lead to content staleness and lower engagement."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Rating Trends in Netflix's Catalog**"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with a specified size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a grouped bar chart to compare ratings and content types\n",
        "sns.countplot(x=\"rating\", hue=\"type\", data=netflix_df)\n",
        "\n",
        "# Set the title and labels for the chart\n",
        "plt.title(\"Rating vs. Type\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend(title=\"Type\")\n",
        "\n",
        "# Print count values on the bars\n",
        "ax = plt.gca()\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "# Show the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is a variant of the bar plot, tailor-made for visualizing the distribution of a categorical variable. It excels at displaying the frequency of various categories and is especially handy for comparing the occurrences of different categories within the dataset.\n"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Adults\" Rating: There are significantly more movies (2595) than TV shows (1025) with the \"Adults\" rating, indicating a preference for movies in this category.\n",
        "\n",
        "\"Teens\" Rating: Only movies (386) are available with the \"Teens\" rating, while there are no TV shows, suggesting a focus on movie content for teenagers.\n",
        "\n",
        "\"Young Adults\" Rating: The distribution between movies (1272) and TV shows (659) is relatively balanced for the \"Young Adults\" rating, providing a diverse range of content for this audience.\n",
        "\n",
        "\"Older Kids\" and \"Kids\" Ratings: Both \"Older Kids\" and \"Kids\" ratings have more movies than TV shows. \"Older Kids\" has 852 movies and 478 TV shows, while \"Kids\" has 267 movies and 246 TV shows, catering to children and older children with a preference for movies."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Impact:\n",
        "\n",
        "1. Targeted Content Allocation: Knowing which content ratings are dominant in specific content types allows Netflix to allocate resources effectively. Producing more content within popular rating categories can attract and retain subscribers, contributing to growth.\n",
        "\n",
        "2. Diverse Audience Engagement: Balanced distribution of the \"Young Adults\" rating between movies and TV shows caters to a diverse audience within that age group, enhancing engagement and satisfaction.\n",
        "\n",
        "Negative Impact:\n",
        "\n",
        "1. Missed Opportunity for Teens: The absence of TV shows for the \"Teens\" rating might lead to missed opportunities to attract younger viewers seeking TV show content. This could result in negative growth among teenagers.\n",
        "\n",
        "2. Limited Children's TV Shows: The higher count of movies compared to TV shows in the \"Older Kids\" and \"Kids\" categories could limit options for younger viewers who prefer TV shows. This might lead to negative growth among families looking for TV show content for children."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **TV Shows Breakdown by Season**"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to include only TV Shows\n",
        "tv_df = netflix_df[netflix_df['type'] == 'TV Show']\n",
        "\n",
        "# Count the number of TV shows for each duration (number of seasons)\n",
        "tv_duration_counts = tv_df['duration'].value_counts().reset_index()\n",
        "\n",
        "# Create a pie chart using Plotly\n",
        "fig = px.pie(tv_duration_counts, values='duration', names='index', color_discrete_sequence=px.colors.sequential.Greens)\n",
        "\n",
        "# Update the layout and appearance of the pie chart\n",
        "fig.update_layout(title=\"Season-Wise Distribution of TV Shows\")\n",
        "fig.update_traces(\n",
        "    textposition='inside',\n",
        "    textinfo='percent+label',\n",
        "    textfont_size=20,\n",
        "    marker=dict(line=dict(color='RebeccaPurple', width=2))\n",
        ")\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart is an effective choice for visualizing the distribution of TV shows on Netflix based on the number of seasons. It provides a clear and concise representation of the proportion of TV shows in each season category, allowing for easy visual comparison of these proportions."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "1. Diverse Content Strategy: Netflix's diverse content strategy, including both single-season and multi-season shows, caters to a wide range of viewer preferences, potentially attracting and retaining a broader audience.\n",
        "\n",
        "2. Emphasis on Shorter Formats: The dominance of single-season shows aligns with viewer trends favoring concise storytelling, potentially increasing viewer satisfaction and engagement.\n",
        "\n",
        "3. Variety in Multi-Season Shows: Offering multi-season shows in various ranges provides viewers with a choice of ongoing series and longer story arcs, enhancing viewer loyalty and engagement.\n",
        "\n",
        "4. Viewer Engagement with Long-Running Shows: The presence of TV shows with many seasons suggests that some series have successfully maintained viewer engagement over time, potentially leading to long-term subscriber retention.\n",
        "\n",
        "Potential Negative Impact:\n",
        "\n",
        "1. Production Costs and Sustained Engagement: Longer-running shows require sustained resources and consistent audience interest. A drop in production quality or viewer engagement in these shows could lead to negative growth.\n",
        "\n",
        "2. Content Quality and Viewer Satisfaction: Maintaining a balance between quantity and quality is crucial. An excessive focus on producing short or long shows at the expense of quality might lead to viewer dissatisfaction and churn.\n",
        "\n",
        "3. Changing Viewer Preferences: The shifting distribution of show durations could indicate evolving viewer preferences. Failure to adapt content offerings to these changing preferences may result in negative growth in certain segments.\n",
        "\n",
        "4. Content Gaps: The gaps in the distribution, such as the absence of mid-range shows (7-9 seasons), might signify missed opportunities to capture viewer interest. Neglecting these gaps could lead to potential negative growth within specific audience segments."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix's content strategy should prioritize viewer behavior and feedback analysis to gauge content preferences. Ongoing competitor analysis ensures Netflix remains on-trend and identifies market gaps. Market research and surveys provide insight into viewer demographics, preferences, and emerging trends. Content testing through A/B trials and pilot programs minimizes risk and optimizes content choices.\n",
        "\n",
        "Strategic partnerships with content creators, studios, and production companies foster exclusive and innovative offerings. Investment in original content maintains a competitive edge. Data analytics guides content decisions, such as renewals, acquisitions, and production. Flexibility and adaptability to changing viewer preferences are essential. Balancing quantity and quality ensures diverse and high-quality content. Global expansion targets diverse audiences, broadening the subscriber base. Personalization, driven by data, enhances engagement and retention."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Netflix's Top 10 Directors**"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the DataFrame into movies and TV shows\n",
        "df_movies = netflix_df[netflix_df['type'] == 'Movie']\n",
        "df_tvshows = netflix_df[netflix_df['type'] == 'TV Show']\n",
        "\n",
        "# Create a figure with a specified size\n",
        "plt.figure(figsize=(23, 8))\n",
        "\n",
        "# Loop through movies and TV shows dataframes\n",
        "for dataframe, content_type, subplot_index in ((df_movies, 'Movies', 0), (df_tvshows, 'TV Shows', 1)):\n",
        "    # Create a subplot\n",
        "    plt.subplot(1, 2, subplot_index + 1)\n",
        "\n",
        "    # Group by director and count the number of unique titles\n",
        "    df_director = dataframe.groupby(['director']).agg({'title': 'nunique'}).reset_index().sort_values(by=['title'], ascending=False)[1:10]\n",
        "\n",
        "    # Create a barplot for the top 10 directors\n",
        "    plots = sns.barplot(y=\"director\", x='title', data=df_director, palette='Paired')\n",
        "\n",
        "    # Set the title and formatting for the plot\n",
        "    plt.title(f'Directors Appeared in Most of the {content_type}')\n",
        "    plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "\n",
        "# Show the subplots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The horizontal bar chart with subplots provides a visually effective means of comparing the top directors in both TV shows and movies. This chart offers insights into their contributions to Netflix's content library across different categories."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the concise and paraphrased versions of the information you provided:\n",
        "\n",
        "**Top 10 TV Show Directors:**\n",
        "\n",
        "1. **Diverse Directorship:** Alastair Fothergill leads with 3 shows directed, while others have 2 each.\n",
        "\n",
        "2. **Variety in Content:** Multiple directors contribute to Netflix's TV shows, indicating diversity.\n",
        "\n",
        "3. **Documentaries and Series:** Directors like Alastair Fothergill and Ken Burns excel in documentaries.\n",
        "\n",
        "4. **Continuity in Series:** Directors Shin Won-ho, Iginio Straffi, and Rob Seidenglanz suggest successful series continuations.\n",
        "\n",
        "**Top 10 Movie Directors:**\n",
        "\n",
        "1. **Highly Prolific Directors:** Raúl Campos and Jan Suter top with 18 movies, followed closely by others.\n",
        "\n",
        "2. **Comedy and Stand-Up:** Marcus Raboy, Jay Karas, and Jay Chapman specialize in comedy, including stand-up.\n",
        "\n",
        "3. **Diverse Genres:** Directors like Cathy Garcia-Molina and Youssef Chahine cover various movie genres.\n",
        "\n",
        "4. **Renowned Filmmakers:** Martin Scorsese and Steven Spielberg collaborate with Netflix for original films.\n",
        "\n",
        "5. **Variety in Style:** Diverse director styles contribute to Netflix's broad movie portfolio."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "**Diverse Content Portfolio:** Partnering with directors specializing in various genres can enrich Netflix's content offering, attracting a broader audience and potentially increasing subscribers.\n",
        "\n",
        "**Renowned Filmmakers:** Collaboration with respected directors like Scorsese and Spielberg enhances Netflix's reputation, drawing subscribers seeking high-quality content.\n",
        "\n",
        "**Prolific Directors:** Experienced directors ensure a consistent stream of fresh content, maintaining subscriber engagement.\n",
        "\n",
        "**Catering to Audience Preferences:** A mix of directors covering different genres caters to global audience preferences.\n",
        "\n",
        "Potential Negative Impact:\n",
        "\n",
        "**Overemphasis on Quantity:** Prioritizing quantity over quality may lead to content fatigue and compromise viewer satisfaction.\n",
        "\n",
        "**Lack of Focus:** An extensive director roster could result in a fragmented content strategy, causing viewer confusion.\n",
        "\n",
        "**Risk of Exclusivity:** Dependence on a few renowned directors may lead to content gaps if they work with other platforms.\n",
        "\n",
        "**Niche Versus Mainstream:** The director mix can tilt towards niche or mainstream content, necessitating a balance for diverse audience segments.\n",
        "\n",
        "**Disproportionate Focus:** Dominance of a select group of directors may overshadow emerging talent and innovative storytelling.\n",
        "\n",
        "**Limited Originality:** Excessive reliance on certain directors might hinder originality in content, resulting in repetitive themes and narratives."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Leading Performers in Television and Film**"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows with 'unknown' cast entries\n",
        "filtered_netflix_df = netflix_df[~netflix_df['cast'].str.contains('unknown', case=False, na=False)]\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Separate TV show actors from the 'cast' column\n",
        "top_TVshows_actor = filtered_netflix_df[filtered_netflix_df['type'] == 'TV Show']['cast'].str.split(', ', expand=True).stack()\n",
        "\n",
        "# Create a horizontal bar chart for the top 10 TV show actors\n",
        "a = top_TVshows_actor.value_counts().head(10).plot(kind='barh', ax=ax[0])\n",
        "a.set_title('Top 10 TV Show Actors', size=15)\n",
        "\n",
        "# Separate movie actors from the 'cast' column\n",
        "top_movie_actor = filtered_netflix_df[filtered_netflix_df['type'] == 'Movie']['cast'].str.split(', ', expand=True).stack()\n",
        "\n",
        "# Create a horizontal bar chart for the top 10 movie actors\n",
        "b = top_movie_actor.value_counts().head(10).plot(kind='barh', ax=ax[1])\n",
        "b.set_title('Top 10 Movie Actors', size=15)\n",
        "\n",
        "# Adjust the layout and spacing of the subplots\n",
        "plt.tight_layout(pad=1.2, rect=[0, 0, 0.95, 0.95])\n",
        "\n",
        "# Show the subplots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A horizontal bar chart with subplots is an effective visual tool for comparing and contrasting the popularity and engagement of top actors in both Netflix TV shows and movies. It offers insights into their performance in each category."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concise and Paraphrased Version:\n",
        "\n",
        "**Top 10 TV Show Actors:**\n",
        "\n",
        "1. **Japanese Voice Actors:** The presence of Japanese voice actors like Takahiro Sakurai, Yuki Kaji, Daisuke Ono, and Ai Kayano in the top TV show actors indicates a strong representation of anime content on Netflix.\n",
        "\n",
        "2. **Dubbed Anime:** The frequent appearance of these voice actors suggests the popularity of dubbed anime content on the platform.\n",
        "\n",
        "3. **Frequent Collaborations:** Junichi Suwabe, Yoshimasa Hosoya, and Yuichi Nakamura also feature prominently, implying consistent collaborations or recurring roles in TV shows.\n",
        "\n",
        "4. **Diverse Genres:** While known for anime, these actors' diverse appearances hint at involvement in various genres beyond animation.\n",
        "\n",
        "**Top 10 Movie Actors:**\n",
        "\n",
        "1. **Bollywood Dominance:** Bollywood stars like Shah Rukh Khan, Akshay Kumar, and Amitabh Bachchan dominate the list, reflecting a significant presence of Indian cinema on Netflix.\n",
        "\n",
        "2. **Indian Cinema Showcase:** High counts for actors like Anupam Kher, Om Puri, Naseeruddin Shah, and Paresh Rawal underscore the platform's focus on showcasing classic and contemporary Indian cinema.\n",
        "\n",
        "3. **Versatile Actors:** These actors exhibit versatility across various genres in Indian cinema.\n",
        "\n",
        "4. **Global Appeal of Bollywood:** The popularity of these actors indicates that Bollywood films have a global audience on Netflix."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Impact:**\n",
        "\n",
        "1. **Diverse Audience Appeal:** Featuring Japanese voice actors and Bollywood stars broadens Netflix's global audience appeal.\n",
        "\n",
        "2. **Boosted Engagement:** High actor appearances deepen viewer engagement and attract new subscribers.\n",
        "\n",
        "3. **Regional Focus:** Prominent Bollywood actors highlight Netflix's regional content commitment, attracting subscribers in regions keen on Indian cinema.\n",
        "\n",
        "4. **Effective Collaborations:** Consistent actor appearances suggest fruitful collaborations, resulting in high-quality content and positive audience reception.\n",
        "\n",
        "**Negative Impact:**\n",
        "\n",
        "1. **Overreliance on Actors:** Overemphasizing a few actors can lead to viewer fatigue and perceptions of repetitiveness.\n",
        "\n",
        "2. **Cultural Balance Concerns:** Underrepresentation of specific regions or cultures can dissatisfy certain audience groups.\n",
        "\n",
        "3. **Competitive Limitations:** Heavy reliance on specific actors may hinder competition with platforms having exclusive content deals.\n",
        "\n",
        "4. **Long-Term Success:** Platform success depends on factors beyond actor popularity, including content quality and viewer experience.\n",
        "\n"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Annual Count of Movies and TV Shows Released and Added to Netflix**"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots for Movies and TV Shows\n",
        "plt.figure(figsize=(20, 6))\n",
        "\n",
        "for i, j, k in ((df_movies, 'Movies', 0), (df_tvshows, 'TV Shows', 1)):\n",
        "    # Create a subplot\n",
        "    plt.subplot(1, 2, k + 1)\n",
        "\n",
        "    # Group data by release year and aggregate unique titles\n",
        "    df_release_year = i.groupby(['release_year']).agg({'title': 'nunique'}).reset_index().sort_values(\n",
        "        by=['release_year'], ascending=False)[:14]\n",
        "\n",
        "    # Create a bar plot\n",
        "    plots = sns.barplot(x='release_year', y='title', data=df_release_year, palette='husl')\n",
        "\n",
        "    # Set title and labels\n",
        "    plt.title(f'{j} released by year')\n",
        "    plt.ylabel(f\"Number of {j} released\")\n",
        "\n",
        "    # Add a grid\n",
        "    plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "    # Annotate each bar with its height\n",
        "    for bar in plots.patches:\n",
        "        plots.annotate(bar.get_height(),\n",
        "                        (bar.get_x() + bar.get_width() / 2,\n",
        "                         bar.get_height()), ha='center', va='center',\n",
        "                        size=12, xytext=(0, 8),\n",
        "                        textcoords='offset points')\n",
        "\n",
        "# Show the figure with subplots for Movies and TV Shows\n",
        "plt.show()\n",
        "\n",
        "# Create another figure with two subplots for Movies and TV Shows\n",
        "plt.figure(figsize=(20, 6))\n",
        "\n",
        "for i, j, k in ((df_movies, 'Movies', 0), (df_tvshows, 'TV Shows', 1)):\n",
        "    # Create a subplot\n",
        "    plt.subplot(1, 2, k + 1)\n",
        "\n",
        "    # Group data by year added and aggregate unique titles\n",
        "    df_country = i.groupby(['year_added']).agg({'title': 'nunique'}).reset_index().sort_values(\n",
        "        by=['year_added'], ascending=False)\n",
        "\n",
        "    # Create a bar plot\n",
        "    plots = sns.barplot(x='year_added', y='title', data=df_country, palette='husl')\n",
        "\n",
        "    # Set title and labels\n",
        "    plt.title(f'{j} added to Netflix by year')\n",
        "    plt.ylabel(f\"Number of {j} added on Netflix\")\n",
        "\n",
        "    # Add a grid\n",
        "    plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "    # Annotate each bar with its height\n",
        "    for bar in plots.patches:\n",
        "        plots.annotate(bar.get_height(),\n",
        "                        (bar.get_x() + bar.get_width() / 2,\n",
        "                         bar.get_height()), ha='center', va='center',\n",
        "                        size=12, xytext=(0, 8),\n",
        "                        textcoords='offset points')\n",
        "\n",
        "# Show the figure with subplots for Movies and TV Shows\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining the histogram and countplot offers a holistic perspective on the distribution of release years for content and the evolving mix of content genres across different time periods. This combined visualization facilitates straightforward comparisons, the recognition of recurring trends, and the extraction of valuable insights into Netflix's content tactics and viewer inclinations."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Release Year Insights:\n",
        "\n",
        "- Recent years, especially from 2016 to 2020, witnessed a surge in both TV show and movie releases, likely due to the rise of streaming platforms and original content.\n",
        "  \n",
        "Top 15 Years for TV Shows:\n",
        "\n",
        "- In 2020, the highest number of TV shows were released, closely followed by 2019 and 2018, indicating a trend of increased TV show production in recent years.\n",
        "\n",
        "Top 15 Years for Movies:\n",
        "\n",
        "- Similarly, 2017 saw the most movie releases, followed by 2018, 2016, and 2019, pointing to a notable rise in movie production in recent times.\n"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "1. **Increased Content Production:** Netflix's growing content library attracts and retains subscribers with diverse choices.\n",
        "\n",
        "2. **Original Content Focus:** Emphasizing original content sets Netflix apart and engages subscribers.\n",
        "\n",
        "3. **Genre Variety:** Diverse genres cater to a broader audience.\n",
        "\n",
        "4. **Global Reach:** International content expansion broadens Netflix's audience.\n",
        "\n",
        "5. **Expanding Library:** Consistent content growth maintains user engagement.\n",
        "\n",
        "**Challenges and Considerations:**\n",
        "\n",
        "1. **Quality vs. Quantity:** Balancing content quantity with quality is crucial.\n",
        "\n",
        "2. **Viewer Fatigue:** Overwhelming releases may reduce engagement.\n",
        "\n",
        "3. **Market Saturation:** Increasing competition poses acquisition challenges.\n"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Countries with the Broadest Netflix Content Selection**"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure for the first plot\n",
        "plt.figure(figsize=(18, 5))\n",
        "plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "# Find the top 15 countries with the most content\n",
        "top_countries = netflix_df['country'].value_counts().index[:15]\n",
        "\n",
        "# Create a countplot to visualize content distribution by country and type\n",
        "sns.countplot(x=netflix_df['country'], order=top_countries, hue=netflix_df['type'], palette=\"Set1\")\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('Top 15 countries with the most content', fontsize=15, fontweight='bold')\n",
        "plt.legend(title='Type')\n",
        "\n",
        "# Create a figure for the second set of plots\n",
        "plt.figure(figsize=(20, 8))\n",
        "\n",
        "# Separate the data into Movies and TV Shows\n",
        "df_movies = netflix_df[netflix_df['type'] == 'Movie']\n",
        "df_tvshows = netflix_df[netflix_df['type'] == 'TV Show']\n",
        "\n",
        "for df, content_type in [(df_movies, 'Movies'), (df_tvshows, 'TV Shows')]:\n",
        "    # Create subplots for Movies and TV Shows\n",
        "    plt.subplot(1, 2, 1 if content_type == 'Movies' else 2)\n",
        "\n",
        "    # Count the top 10 countries with the most content of the current type\n",
        "    df_country = df['country'].value_counts().head(10).reset_index()\n",
        "    df_country.columns = ['country', 'count']\n",
        "\n",
        "    # Create a barplot to visualize the top countries for the current type\n",
        "    plots = sns.barplot(y=\"country\", x='count', data=df_country, palette='Set1')\n",
        "    plt.title(f'Top 10 countries launching {content_type}', fontsize=15, fontweight='bold')\n",
        "    plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "    # Add labels to the bars\n",
        "    for i, value in enumerate(df_country['count']):\n",
        "        plots.text(value + 10, i, str(value), ha='center', va='center')\n",
        "\n",
        "# Adjust layout for better visualization\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Top 15 Countries by Content:** A countplot illustrates the content distribution among the top 15 countries on Netflix. It offers a quick comparison of content types in these countries.\n",
        "\n",
        "2. **Top 10 Countries for Movie Releases:** A bar chart showcases the top 10 countries with continuous movie releases, revealing production trends and potential collaborations.\n",
        "\n",
        "3. **Top 10 Countries for TV Show Releases:** Another bar chart displays the top 10 countries with frequent TV show releases, highlighting active TV show production trends."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **United States Dominance:** The United States leads in content production, producing over double the number of TV shows compared to the United Kingdom and more than triple the number of movies compared to India.\n",
        "\n",
        "2. **Indian Growth:** India is the second-largest TV show producer and experiencing rapid content consumption growth due to streaming popularity, a growing middle class, and rising incomes.\n",
        "\n",
        "3. **South Korean Influence:** South Korea is a major global player known for popular dramas and comedies, with the \"Korean Wave\" boosting the visibility of its TV shows worldwide.\n",
        "\n",
        "4. **Canadian Impact:** Canada is a significant TV show producer, hosting popular series like \"Schitt's Creek\" and \"The Handmaid's Tale,\" with government support attracting foreign investment and job creation.\n",
        "\n",
        "5. **Chinese Media Control:** China, with a massive population, has a rising appetite for content but faces media control limitations, resulting in limited access to foreign TV shows and movies."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "1. **Market Expansion:** Identify new markets like India with growing content consumption for targeted production.\n",
        "\n",
        "2. **Global Strategies:** Learn from the success of South Korean TV shows to create content with international appeal.\n",
        "\n",
        "3. **Strategic Partnerships:** Collaborate with streaming services to broaden content distribution.\n",
        "\n",
        "**Challenges and Considerations:**\n",
        "\n",
        "1. **Chinese Media Control:** Stringent media control in China may hinder content distribution opportunities.\n",
        "\n",
        "2. **Competitive Landscape:** Increasing global competition may pose challenges for smaller production companies in the industry.\n",
        "\n",
        "These insights can guide strategic decisions for content production companies, opening up opportunities for growth while being mindful of potential challenges."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Netflix's Trending Genres: Viewer Preferences**"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure for the first plot\n",
        "plt.figure(figsize=(23, 8))\n",
        "\n",
        "# Group data by listed_in (genres) and aggregate unique titles, then sort by popularity\n",
        "df_genre = df.groupby(['listed_in']).agg({'title': 'nunique'}).reset_index().sort_values(by=['title'], ascending=False)[:10]\n",
        "\n",
        "# Create a bar plot to visualize the most popular genres\n",
        "plots = sns.barplot(y=\"listed_in\", x='title', data=df_genre)\n",
        "plt.title(f'Most popular genres on Netflix')\n",
        "plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "# Add labels to the bars\n",
        "plots.bar_label(plots.containers[0])\n",
        "\n",
        "# Show the first plot\n",
        "plt.show()\n",
        "\n",
        "# Create a figure for the second set of plots\n",
        "plt.figure(figsize=(23, 8))\n",
        "\n",
        "for i, j, k in ((df_movies, 'Movies', 0), (df_tvshows, 'TV Shows', 1)):\n",
        "    # Create subplots for Movies and TV Shows\n",
        "    plt.subplot(1, 2, k + 1)\n",
        "\n",
        "    # Group data by listed_in (genres) and aggregate unique titles, then sort by popularity\n",
        "    df_genre = i.groupby(['listed_in']).agg({'title': 'nunique'}).reset_index().sort_values(by=['title'], ascending=False)[:10]\n",
        "\n",
        "    # Create a bar plot to visualize the most popular genres for the current type\n",
        "    plots = sns.barplot(y=\"listed_in\", x='title', data=df_genre, palette='Set1')\n",
        "    plt.title(f'Most popular genres of {j}')\n",
        "    plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "    # Add labels to the bars\n",
        "    plots.bar_label(plots.containers[0])\n",
        "\n",
        "    # Rotate y-axis labels for better readability\n",
        "    plt.yticks(rotation=45)\n",
        "\n",
        "# Adjust layout for better visualization of subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the second set of plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots excel at visualizing categorical data, making them ideal for showcasing Netflix's most popular genres."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **International TV Shows:** The top genre for TV shows indicates a global appetite for content from diverse cultures, possibly due to increasing globalization and the availability of international content on streaming platforms.\n",
        "\n",
        "2. **Crime TV Shows:** Ranking second, crime TV shows offer universal appeal with their suspenseful and exciting nature, drawing viewers of all ages.\n",
        "\n",
        "3. **Kids' TV:** The popularity of kids' TV shows is unsurprising, as they engage young audiences through relatable stories and educational content.\n",
        "\n",
        "4. **British TV Shows:** British TV's high quality, originality, and awards recognition make it a strong fourth, attracting viewers seeking exceptional content.\n",
        "\n",
        "5. **Documentaries:** In fifth place, the interest in documentaries reflects a desire for informative, educational, and entertaining content, fostering a better understanding of the world."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Monthly Netflix Content Additions: Movies and TV Shows**"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure for the set of plots\n",
        "plt.figure(figsize=(23, 8))\n",
        "\n",
        "for i, j, k in ((df_movies, 'Movies', 0), (df_tvshows, 'TV Shows', 1)):\n",
        "    # Create subplots for Movies and TV Shows\n",
        "    plt.subplot(1, 2, k + 1)\n",
        "\n",
        "    # Group data by the month_added and aggregate unique titles\n",
        "    df_month = i.groupby(['month_added']).agg({'title': 'nunique'}).reset_index().sort_values(by=['month_added'], ascending=False)\n",
        "\n",
        "    # Create a bar plot to visualize the number of content added by month\n",
        "    plots = sns.barplot(x='month_added', y='title', data=df_month, palette='husl')\n",
        "    plt.title(f'{j} added to Netflix by month')\n",
        "    plt.ylabel(f\"Number of {j} added on Netflix\")\n",
        "    plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "    # Annotate each bar with its height\n",
        "    for bar in plots.patches:\n",
        "        plots.annotate(bar.get_height(),\n",
        "                       (bar.get_x() + bar.get_width() / 2,\n",
        "                        bar.get_height()), ha='center', va='center',\n",
        "                       size=12, xytext=(0, 8),\n",
        "                       textcoords='offset points')\n",
        "\n",
        "# Show the set of plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created this graph to identify the month with the highest content additions and the year with the lowest additions for movies and TV shows."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **TV Shows**: October, November, and December are the top months for additions.\n",
        "- **Movies**: January, October, and December see the most additions.\n",
        "- **Lowest Activity**: February experiences the lowest additions for both movies and TV shows on Netflix."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v751JlcuVIw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothetical Statement 1:**\n",
        "\n",
        "Null Hypothesis: There is no substantial disparity in the rating proportions between drama and comedy movies available on Netflix.\n",
        "\n",
        "Alternative Hypothesis: A significant difference exists in the rating proportions between drama and comedy movies on Netflix.\n",
        "\n",
        "**Hypothetical Statement 2:**\n",
        "\n",
        "Null Hypothesis: The average duration of TV shows introduced in 2020 on Netflix does not differ significantly from the average duration of TV shows introduced in 2021.\n",
        "\n",
        "Alternative Hypothesis: The average duration of TV shows added in 2020 on Netflix significantly differs from the average duration of TV shows added in 2021.\n",
        "\n",
        "**Hypothetical Statement 3:**\n",
        "\n",
        "Null Hypothesis: The proportion of American-produced TV shows added to Netflix is not substantially distinct from the proportion of American-produced movies added to Netflix.\n",
        "\n",
        "Alternative Hypothesis: There is a significant difference in the proportion of American-produced TV shows and movies added to Netflix."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: There is no substantial disparity in the rating proportions between drama and comedy movies available on Netflix.\n",
        "\n",
        "Alternative Hypothesis: A significant difference exists in the rating proportions between drama and comedy movies on Netflix."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library for the z-test\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Subset the data to only include drama and comedy movies\n",
        "subset = netflix_df[netflix_df['listed_in'].str.contains('Dramas') | netflix_df['listed_in'].str.contains('Comedies')]\n",
        "\n",
        "# Calculate the proportion of drama and comedy movies in the subset\n",
        "drama_prop = len(subset[subset['listed_in'].str.contains('Dramas')]) / len(subset)\n",
        "comedy_prop = len(subset[subset['listed_in'].str.contains('Comedies')]) / len(subset)\n",
        "\n",
        "# Set up the parameters for the z-test\n",
        "count = [int(drama_prop * len(subset)), int(comedy_prop * len(subset))]  # Number of successes (dramas and comedies)\n",
        "nobs = [len(subset), len(subset)]  # Number of observations (total count)\n",
        "alternative = 'two-sided'  # Two-sided test to compare proportions\n",
        "\n",
        "# Perform the z-test\n",
        "z_stat, p_value = proportions_ztest(count=count, nobs=nobs, alternative=alternative)\n",
        "\n",
        "# Print the z-statistic and p-value\n",
        "print('z-statistic: ', z_stat)\n",
        "print('p-value: ', p_value)\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results of the z-test based on the p-value and significance level\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have conducted a statistical analysis using the z-test for proportions to calculate the p-value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The z-test for proportions was selected because it's suitable for comparing the proportions of two categorical variables (drama and comedy movies) in a sample. It helps us assess whether the observed difference in proportions is statistically significant, by testing the null hypothesis that there's no difference between the proportions."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: The average duration of TV shows introduced in 2020 on Netflix does not differ significantly from the average duration of TV shows introduced in 2021.\n",
        "\n",
        "Alternative Hypothesis: The average duration of TV shows added in 2020 on Netflix significantly differs from the average duration of TV shows added in 2021."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library for the t-test\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Create separate dataframes for TV shows in 2020 and 2021\n",
        "tv_2020 = netflix_df[(netflix_df['type'] == 'TV Show') & (netflix_df['release_year'] == 2020)]\n",
        "tv_2021 = netflix_df[(netflix_df['type'] == 'TV Show') & (netflix_df['release_year'] == 2021)]\n",
        "\n",
        "# Perform a two-sample t-test to compare the average durations\n",
        "# equal_var=False assumes unequal variances between the two groups\n",
        "t, p = ttest_ind(tv_2020['duration'].astype(int), tv_2021['duration'].astype(int), equal_var=False)\n",
        "print('t-value: ', t)\n",
        "print('p-value: ', p)\n",
        "\n",
        "# Print the results of the t-test\n",
        "if p < 0.05:\n",
        "    print('Reject null hypothesis.')\n",
        "    print('The average duration of TV shows added in the year 2020 on Netflix is significantly different from the average duration of TV shows added in the year 2021.')\n",
        "else:\n",
        "    print('Failed to reject null hypothesis.')\n",
        "    print('The average duration of TV shows added in the year 2020 on Netflix is not significantly different from the average duration of TV shows added in the year 2021.')"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The P-value was obtained using a two-sample t-test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two-sample t-test was selected to compare the means of two different samples (TV shows added in 2020 vs. 2021) for significance. We assume unequal variances between the two samples, considering the unlikely scenario of them having the same variance."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: The proportion of American-produced TV shows added to Netflix is not substantially distinct from the proportion of American-produced movies added to Netflix.\n",
        "\n",
        "Alternative Hypothesis: There is a significant difference in the proportion of American-produced TV shows and movies added to Netflix."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library for the z-test\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Calculate the proportion of TV shows and movies produced in the United States\n",
        "tv_proportion = np.sum(df_tvshows['country'].str.contains('United States')) / len(df_tvshows)\n",
        "movie_proportion = np.sum(df_movies['country'].str.contains('United States')) / len(df_movies)\n",
        "\n",
        "# Set up the parameters for the z-test\n",
        "count = [int(tv_proportion * len(df_tvshows)), int(movie_proportion * len(df_movies))]  # Number of successes (TV shows and movies produced in the US)\n",
        "nobs = [len(df_tvshows), len(df_movies)]  # Number of observations (total count of TV shows and movies)\n",
        "alternative = 'two-sided'  # Two-sided test to compare proportions\n",
        "\n",
        "# Perform the z-test\n",
        "z_stat, p_value = proportions_ztest(count=count, nobs=nobs, alternative=alternative)\n",
        "\n",
        "# Print the z-statistic and p-value\n",
        "print('z-statistic: ', z_stat)\n",
        "print('p-value: ', p_value)\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results of the z-test based on the p-value and significance level\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The P-value was obtained using a two-sample proportion test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We selected this test because it's suitable for comparing two proportions and helps us assess whether the observed difference is statistically significant or a result of chance."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a subplot with two graphs side by side\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot a distribution plot (histogram) for the 'release_year' column\n",
        "sns.distplot(x=netflix_df['release_year'], ax=ax[0])\n",
        "ax[0].set_title('Distribution Plot for Release Year')\n",
        "\n",
        "# Plot a box plot to visualize outliers in the 'release_year' column\n",
        "sns.boxplot(data=netflix_df, ax=ax[1])\n",
        "ax[1].set_title('Box Plot for Release Year')\n",
        "\n",
        "# Display the subplots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since nearly all the data is in textual format except for the release year, and the data needed for clustering/modeling is in textual form, outlier handling is unnecessary."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Textual Data Preprocessing"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Textual Columns"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns from the DataFrame\n",
        "columns_to_drop = ['month_added', 'day_added', 'year_added']\n",
        "netflix_df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Create a new feature \"content_detail\" by combining values from other textual attributes\n",
        "netflix_df[\"content_detail\"] = netflix_df[\"cast\"] + \" \" + netflix_df[\"director\"] + \" \" + netflix_df[\"listed_in\"] + \" \" + netflix_df[\"type\"] + \" \" + netflix_df[\"rating\"] + \" \" + netflix_df[\"country\"] + \" \" + netflix_df[\"description\"]\n",
        "\n",
        "# Check the DataFrame to see the changes\n",
        "netflix_df.head(5)"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the \"content_detail\" column values to lowercase\n",
        "netflix_df['content_detail'] = netflix_df['content_detail'].str.lower()\n",
        "\n",
        "# Checking the result for a specific row (e.g., row 281)\n",
        "content_detail_281 = netflix_df.iloc[281]['content_detail']\n",
        "content_detail_281"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuations(text):\n",
        "    '''This function is used to remove the punctuations from the given sentence'''\n",
        "\n",
        "    # Importing the 'string' library, which contains a string of all punctuation marks.\n",
        "    import string\n",
        "\n",
        "    # Creating a translator object that maps each punctuation mark to None (deletes it).\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    # Return the input text with punctuation marks removed.\n",
        "    return text.translate(translator)\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the remove_punctuations function to the \"content_detail\" column\n",
        "netflix_df['content_detail'] = netflix_df['content_detail'].apply(remove_punctuations)\n",
        "\n",
        "# Checking the result for a specific row (e.g., row 281)\n",
        "content_detail_281 = netflix_df.iloc[281]['content_detail']"
      ],
      "metadata": {
        "id": "amhvNluReitt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url_and_numbers(text):\n",
        "    \"\"\"\n",
        "    Remove URLs and numbers from the given text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text from which URLs and numbers will be removed.\n",
        "\n",
        "    Returns:\n",
        "        str: The text with URLs and numbers removed.\n",
        "    \"\"\"\n",
        "    # Regular expression pattern to match URLs\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    # Remove URLs by replacing them with an empty string\n",
        "    text = re.sub(url_pattern, '', text)\n",
        "\n",
        "    # Remove digits and non-alphabet characters by replacing them with spaces\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the 'remove_url_and_numbers' function to the 'content_detail' column\n",
        "netflix_df['content_detail'] = netflix_df['content_detail'].apply(remove_url_and_numbers)\n",
        "\n",
        "# Check the result for a specific observation (e.g., row 281)\n",
        "specific_observation = netflix_df.iloc[281]['content_detail']\n",
        "\n",
        "# Print or inspect the result\n",
        "print(specific_observation)"
      ],
      "metadata": {
        "id": "zFgoUoj9fQYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK library and downloading English stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Create a set of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Display the set of stopwords\n",
        "print(stop_words)\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords_and_whitespaces(text):\n",
        "    \"\"\"\n",
        "    Remove stopwords and extra whitespaces from the given sentence.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input sentence.\n",
        "\n",
        "    Returns:\n",
        "        str: The sentence with stopwords removed and extra whitespaces reduced.\n",
        "    \"\"\"\n",
        "    # Tokenize the sentence and filter out stopwords\n",
        "    words = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "    # Join the filtered words back into a sentence with a single space separator\n",
        "    cleaned_text = \" \".join(words)\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
        "\n",
        "    return cleaned_text\n"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the 'remove_stopwords_and_whitespaces' function to the 'content_detail' column\n",
        "netflix_df['content_detail'] = netflix_df['content_detail'].apply(remove_stopwords_and_whitespaces)\n",
        "\n",
        "# Check the result for a specific observation (e.g., row 281)\n",
        "specific_observation = netflix_df.iloc[281]['content_detail']\n",
        "\n",
        "# Print or inspect the result\n",
        "print(specific_observation)"
      ],
      "metadata": {
        "id": "jxNmFZWafrPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the NLTK 'punkt' dataset for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize the 'content_detail' column\n",
        "netflix_df['content_detail'] = netflix_df['content_detail'].apply(nltk.word_tokenize)\n",
        "\n",
        "# Check the result for a specific observation (e.g., row 281)\n",
        "specific_observation = netflix_df.iloc[281]['content_detail']\n",
        "\n",
        "# Print or inspect the result\n",
        "print(specific_observation)"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the WordNetLemmatizer from the nltk.stem module\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Create an instance of the WordNetLemmatizer\n",
        "wordnet = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_sentence(text):\n",
        "    \"\"\"\n",
        "    Lemmatize the words in the given sentence.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input sentence.\n",
        "\n",
        "    Returns:\n",
        "        str: The sentence with words lemmatized.\n",
        "    \"\"\"\n",
        "    # Lemmatize each word in the sentence\n",
        "    text = [wordnet.lemmatize(word) for word in text]\n",
        "\n",
        "    # Join the lemmatized words back into a sentence with a space separator\n",
        "    text = \" \".join(text)\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "EWoHOaKLgUyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the NLTK datasets required for lemmatization\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Apply the 'lemmatizing_sentence' function to the 'content_detail' column\n",
        "netflix_df['content_detail'] = netflix_df['content_detail'].apply(lemmatize_sentence)\n",
        "\n",
        "# Check the result for a specific observation (e.g., row 281)\n",
        "specific_observation = netflix_df.iloc[281]['content_detail']\n",
        "\n",
        "# Print or inspect the result\n",
        "print(specific_observation)"
      ],
      "metadata": {
        "id": "zKcATG1NgZIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have chosen Lemmatization over Stemming for our project for the following reasons:\n",
        "\n",
        "1. Enhanced Accuracy: Unlike Stemming, which simply trims word suffixes, Lemmatization considers word meanings and context, resulting in a more precise base form.\n",
        "\n",
        "2. Handling Varied Inflections: Lemmatization can manage diverse inflections such as plurals, verb tenses, and comparisons, making it valuable for natural language processing tasks.\n",
        "\n",
        "3. Creation of Real Words: Lemmatization consistently generates valid dictionary words, simplifying the interpretation of text analysis outcomes.\n",
        "\n",
        "4. Improved Text Comprehension: By reducing words to their base forms, Lemmatization aids in better comprehension of sentence context and meaning.\n",
        "\n",
        "5. Multilingual Support: While Stemming may be limited to English, Lemmatization proves effective across numerous languages, rendering it a versatile text processing technique."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the 'content_detail' column into words and apply POS tagging\n",
        "netflix_df['pos_tags'] = netflix_df['content_detail'].apply(nltk.word_tokenize).apply(nltk.pos_tag)\n",
        "\n",
        "# Display the first 5 rows of the DataFrame to check the result\n",
        "print(netflix_df.head(5))\n"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create an instance of the TF-IDF vectorizer with a maximum of 30000 features to avoid memory issues\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=30000)\n",
        "\n",
        "# Fit the TF-IDF vectorizer on the 'content_detail' column of the DataFrame\n",
        "x = tfidf_vectorizer.fit_transform(netflix_df['content_detail'])\n",
        "\n",
        "# Print the shape of the resulting document-term matrix\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted for TF-IDF vectorization instead of BAG OF WORDS because it allows me to consider the significance of each word within my document. TF-IDF also assigns greater weight to uncommon words that are exclusive to my content, which, in turn, enhances their importance in the representation."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In textual data processing, I had to deal with the creation of 30,000 attributes during text vectorization, resulting in a vast number of columns that posed challenges for my local machine. To address this issue, I decided to employ Principal Component Analysis (PCA) techniques to effectively reduce the dimensions of this large sparse matrix."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PCA from sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create a PCA object with the desired number of components (you can specify the number of components as a parameter if needed)\n",
        "pca = PCA()\n",
        "\n",
        "# Fit the PCA model on the TF-IDF matrix (convert to dense array using toarray() if necessary)\n",
        "pca.fit(x.toarray())\n",
        "\n",
        "# Calculate the percentage of variance explained by each component\n",
        "variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Print the explained variance for each component\n",
        "print(f\"Explained variance by each component: {variance}\")\n"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure and axis for the plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the cumulative explained variance ratio versus the number of components\n",
        "ax.plot(range(1, len(variance) + 1), np.cumsum(pca.explained_variance_ratio_))\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Number of Components')\n",
        "ax.set_ylabel('Percent of Variance Captured')\n",
        "ax.set_title('PCA Analysis')\n",
        "\n",
        "# Add gridlines for clarity\n",
        "plt.grid(linestyle='--', linewidth=0.3)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HWOzmThthoaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot displayed above, it's evident that 7770 principal components are sufficient to capture 100% of the variance. However, for our specific case, we will focus on retaining only the number of principal components necessary to capture 95% of the variance."
      ],
      "metadata": {
        "id": "yKUSFEEkhs9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a PCA object with n_components set to capture 95% of variance\n",
        "pca_tuned = PCA(n_components=0.95)\n",
        "\n",
        "# Fit and transform the PCA model on the TF-IDF matrix (convert to dense array using toarray() if necessary)\n",
        "pca_tuned.fit(x.toarray())\n",
        "x_transformed = pca_tuned.transform(x.toarray())\n",
        "\n",
        "# Check the shape of the transformed matrix\n",
        "transformed_shape = x_transformed.shape\n",
        "\n",
        "# Print the shape to see the dimensions\n",
        "print(f\"Shape of transformed matrix: {transformed_shape}\")"
      ],
      "metadata": {
        "id": "SZvi_PEZhx2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose to implement PCA (Principal Component Analysis) for dimensionality reduction in our project. PCA is a commonly used technique for reducing the dimensionality of high-dimensional datasets while preserving the essential information present in the original data.\n",
        "\n",
        "The core concept behind PCA involves identifying the principal components of the data, which are linear combinations of the original features that capture the maximum variance within the dataset. Through the projection of data onto these principal components, PCA effectively reduces the number of dimensions while retaining the majority of the original data's important characteristics.\n",
        "\n",
        "PCA is a favored choice for dimensionality reduction due to its simplicity of implementation, computational efficiency, and widespread availability in various data analysis software packages. Moreover, it has undergone extensive research and has a solid theoretical foundation, which establishes it as a dependable and well-understood method."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Means Clustering - ML Model"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Create an instance of the K-Means clustering model with a specified random state\n",
        "model = KMeans(random_state=0)\n",
        "\n",
        "# Instantiate the KElbowVisualizer with a range of K values (from 1 to 16 in this case)\n",
        "visualizer = KElbowVisualizer(model, k=(1, 16), locate_elbow=False)\n",
        "\n",
        "# Fit the data (transformed by PCA) to the visualizer\n",
        "visualizer.fit(x_transformed)\n",
        "\n",
        "# Finalize and display the figure\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, it appears that there might be an elbow forming at the 2-cluster point. However, before making a definitive decision, let's create another chart that iterates over the same range of cluster numbers and calculates the Silhouette Score at each point.\n",
        "\n",
        "But what exactly is the Silhouette Score?\n",
        "\n",
        "The Silhouette Score serves as a metric to assess how closely an object aligns with its own cluster in comparison to other clusters. It plays a crucial role in evaluating the quality of clustering, with a higher score indicating that objects are more similar to their respective clusters and less similar to clusters nearby.\n",
        "\n",
        "The Silhouette Score ranges from -1 to 1, where a score of 1 signifies that the object is an excellent match for its own cluster and poorly matches neighboring clusters. Conversely, a score of -1 suggests that the object is a poor match for its own cluster but aligns well with neighboring clusters."
      ],
      "metadata": {
        "id": "ePpCRjeivFna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Create an instance of the K-Means clustering model\n",
        "model = KMeans(random_state=0)\n",
        "\n",
        "# Instantiate the KElbowVisualizer with a range of K values (from 2 to 16 in this case)\n",
        "# Specify metric='silhouette' to use the silhouette score for evaluation\n",
        "# Specify timings=True to measure the time taken for each K value\n",
        "visualizer = KElbowVisualizer(model, k=(2, 16), metric='silhouette', timings=True, locate_elbow=False)\n",
        "\n",
        "# Fit the transformed data (from PCA) to the visualizer\n",
        "visualizer.fit(x_transformed)\n",
        "\n",
        "# Finalize and display the figure\n",
        "visualizer.show()\n"
      ],
      "metadata": {
        "id": "VBU7drTXvLv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Define the range of K values you want to evaluate\n",
        "k_range = range(2, 7)\n",
        "\n",
        "# Loop through each K value and compute the Silhouette score\n",
        "for k in k_range:\n",
        "    # Create a K-Means clustering model with the current K value\n",
        "    Kmodel = KMeans(n_clusters=k)\n",
        "\n",
        "    # Fit the model to the transformed data (from PCA) and get cluster labels\n",
        "    labels = Kmodel.fit_predict(x_transformed)\n",
        "\n",
        "    # Compute the Silhouette score for the current K value\n",
        "    score = silhouette_score(x_transformed, labels)\n",
        "\n",
        "    # Print the Silhouette score for the current K value\n",
        "    print(\"k=%d, Silhouette score=%f\" % (k, score))\n"
      ],
      "metadata": {
        "id": "KiFkdAaGvRW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the insights gathered from the above plots, both the Elbow plot and Silhouette plot suggest that the Silhouette score is notably favorable when using 4 clusters. Therefore, we will proceed with a K-means analysis with 4 clusters.\n",
        "\n",
        "Now, let's visualize how our data points appear once they have been assigned to their respective clusters."
      ],
      "metadata": {
        "id": "FOj9cd0FvVdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a K-Means clustering model with 4 clusters, using the 'k-means++' initialization method\n",
        "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=0)\n",
        "\n",
        "# Predict the cluster labels for each data point and store them in the 'label' variable\n",
        "label = kmeans.fit_predict(x_transformed)\n",
        "\n",
        "# Create a figure for plotting\n",
        "plt.figure(figsize=(10, 6), dpi=120)\n",
        "\n",
        "# Get unique cluster labels\n",
        "unique_labels = np.unique(label)\n",
        "\n",
        "# Plot the results by iterating through each unique cluster label\n",
        "for i in unique_labels:\n",
        "    plt.scatter(x_transformed[label == i, 0], x_transformed[label == i, 1], label=i)\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3kcZ1M47vaeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do indeed have four distinct clusters, but the previous plot was presented in a two-dimensional format. To gain a better understanding of the data, let's create a 3D visualization using the mplot3d library. This will allow us to examine the separated clusters more effectively."
      ],
      "metadata": {
        "id": "XIT7Jf03vex7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library for 3D visualization\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Define colors for each cluster\n",
        "colors = ['r', 'g', 'b', 'y']\n",
        "\n",
        "# Plot the data points in 3D for each cluster\n",
        "for i in range(len(colors)):\n",
        "    ax.scatter(\n",
        "        x_transformed[kmeans.labels_ == i, 2],\n",
        "        x_transformed[kmeans.labels_ == i, 0],\n",
        "        x_transformed[kmeans.labels_ == i, 1],\n",
        "        c=colors[i]\n",
        "    )\n",
        "\n",
        "# Rotate the 3D plot for better visibility\n",
        "ax.view_init(elev=20, azim=-120)\n",
        "\n",
        "# Set labels for each axis\n",
        "ax.set_xlabel('x-axis')\n",
        "ax.set_ylabel('y-axis')\n",
        "ax.set_zlabel('z-axis')\n",
        "\n",
        "# Show the 3D plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RNW5Z67Evk-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! It's clear that we can visually differentiate all four clusters in the 3D plot.\n",
        "\n",
        "Now, to finalize the assignment, let's add a new attribute to the final dataframe and assign each 'Content' to its respective cluster. This will help organize and analyze the data more effectively."
      ],
      "metadata": {
        "id": "Aok8lSjMvpEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the K-Means cluster labels to the DataFrame\n",
        "netflix_df['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "mtJeWVmawCVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries for word cloud generation\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "def kmeans_wordcloud(cluster_number, column_name):\n",
        "    '''\n",
        "    Function for building a word cloud for the movie/shows in a specified cluster.\n",
        "\n",
        "    Args:\n",
        "        cluster_number (int): The cluster number for which you want to create the word cloud.\n",
        "        column_name (str): The name of the column containing text data (e.g., 'content_detail').\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A numpy array representing the generated word cloud image.\n",
        "    '''\n",
        "\n",
        "    # Filter the DataFrame by the specified cluster number and column name, removing NaN and empty strings\n",
        "    df_wordcloud = netflix_df[['kmeans_cluster', column_name]].dropna()\n",
        "    df_wordcloud = df_wordcloud[df_wordcloud['kmeans_cluster'] == cluster_number]\n",
        "    df_wordcloud = df_wordcloud[df_wordcloud[column_name].str.len() > 0]\n",
        "\n",
        "    # Combine all text documents into a single string\n",
        "    text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "    # Create the word cloud\n",
        "    wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"black\").generate(text)\n",
        "\n",
        "    # Convert the word cloud to a numpy array\n",
        "    image_array = wordcloud.to_array()\n",
        "\n",
        "    # Return the numpy array representing the word cloud image\n",
        "    return image_array\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots for plotting word clouds\n",
        "fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(20, 15))\n",
        "\n",
        "# Loop through clusters and attributes to generate and plot word clouds\n",
        "for i in range(4):\n",
        "    for j, col in enumerate(['description', 'listed_in', 'country', 'title']):\n",
        "        axs[j][i].imshow(kmeans_wordcloud(i, col))\n",
        "        axs[j][i].axis('off')\n",
        "        axs[j][i].set_title(f'Cluster {i}, {col}', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Adjust the layout for better visualization\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h-vO2YqSwWgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hierarchial Clustering - ML Model"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries for hierarchical clustering and dendrogram plotting\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "# Perform hierarchical clustering on the transformed data using Ward linkage and Euclidean distance\n",
        "distances_linkage = linkage(x_transformed, method='ward', metric='euclidean')\n",
        "\n",
        "# Create a figure for the dendrogram\n",
        "plt.figure(figsize=(25, 10))\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('All Films/TV Shows')\n",
        "plt.ylabel('Euclidean Distance')\n",
        "\n",
        "# Plot the dendrogram without labels for each observation\n",
        "dendrogram(distances_linkage, no_labels=True)\n",
        "\n",
        "# Show the dendrogram\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GTXqxY573Z5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dendrogram is a tree-like diagram used in clustering analysis to visualize how data points are grouped into clusters. The vertical lines in a dendrogram indicate the distances at which clusters are merged or split. To determine the optimal number of clusters, look for a significant gap between these vertical lines, suggesting a natural break in the data's hierarchy.\n",
        "\n"
      ],
      "metadata": {
        "id": "Dd8xvJ_c3fWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries for Agglomerative Clustering and Silhouette score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Define the range of K values you want to evaluate\n",
        "k_range = range(2, 10)\n",
        "\n",
        "# Loop through each K value and compute the Silhouette score\n",
        "for k in k_range:\n",
        "    # Create an Agglomerative Clustering model with the current K value\n",
        "    model = AgglomerativeClustering(n_clusters=k)\n",
        "\n",
        "    # Fit the model to the transformed data (from PCA) and get cluster labels\n",
        "    labels = model.fit_predict(x_transformed)\n",
        "\n",
        "    # Compute the Silhouette score for the current K value\n",
        "    score = silhouette_score(x_transformed, labels)\n",
        "\n",
        "    # Print the Silhouette score for the current K value\n",
        "    print(\"k=%d, Silhouette score=%f\" % (k, score))\n"
      ],
      "metadata": {
        "id": "oswhG8Yr3lkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the silhouette scores presented above, it is evident that the optimal number of clusters is 2, as indicated by the maximum silhouette score. This conclusion is further supported by the dendrogram analysis, where we can observe that for 2 clusters, the Euclidean distances are at their maximum.\n",
        "\n",
        "Now, let's proceed by plotting the chart once more to visually examine the two distinct clusters that have been formed. This visualization will provide us with a clearer understanding of the data partitioning."
      ],
      "metadata": {
        "id": "qyg3OXC63wCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Agglomerative Clustering model with 2 clusters, using Euclidean distance and Ward linkage\n",
        "Agmodel = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
        "\n",
        "# Predict the cluster labels for each data point and store them in the 'label' variable\n",
        "label = Agmodel.fit_predict(x_transformed)\n",
        "\n",
        "# Create a figure for plotting\n",
        "plt.figure(figsize=(10, 6), dpi=120)\n",
        "\n",
        "# Get unique cluster labels\n",
        "unique_labels = np.unique(label)\n",
        "\n",
        "# Plot the results by iterating through each unique cluster label\n",
        "for i in unique_labels:\n",
        "    plt.scatter(\n",
        "        x_transformed[label == i, 0],\n",
        "        x_transformed[label == i, 1],\n",
        "        label=i\n",
        "    )\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SoS7kgJV4BZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll replot the 3-dimensional graph to provide a clearer view of the clusters."
      ],
      "metadata": {
        "id": "tukkwx1I4FKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library for 3D visualization\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Define colors for each cluster\n",
        "colors = ['r', 'g', 'b', 'y']\n",
        "\n",
        "# Plot the data points in 3D for each cluster\n",
        "for i in range(len(colors)):\n",
        "    ax.scatter(\n",
        "        x_transformed[Agmodel.labels_ == i, 0],\n",
        "        x_transformed[Agmodel.labels_ == i, 1],\n",
        "        x_transformed[Agmodel.labels_ == i, 2],\n",
        "        c=colors[i]\n",
        "    )\n",
        "\n",
        "# Set labels for each axis\n",
        "ax.set_xlabel('x-axis')\n",
        "ax.set_ylabel('y-axis')\n",
        "ax.set_zlabel('z-axis')\n",
        "\n",
        "# Show the 3D plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5ZRqYdbe4Kif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly, we can visually distinguish the two clusters easily. To proceed, let's assign the 'Content(Movies and TV Shows)' to their respective clusters by adding one more attribute to the final dataframe."
      ],
      "metadata": {
        "id": "XrDv_2eh4Oai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the Agglomerative Clustering cluster labels to the DataFrame\n",
        "netflix_df['agglomerative_cluster'] = Agmodel.labels_\n"
      ],
      "metadata": {
        "id": "yJUb-hZN4TXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries for word cloud generation\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "def agglomerative_wordcloud(cluster_number, column_name):\n",
        "    '''\n",
        "    Function for building a word cloud for the movie/shows in a specified cluster using Agglomerative Clustering.\n",
        "\n",
        "    Args:\n",
        "        cluster_number (int): The cluster number for which you want to create the word cloud.\n",
        "        column_name (str): The name of the column containing text data (e.g., 'content_detail').\n",
        "\n",
        "    Returns:\n",
        "        WordCloud: A WordCloud object representing the generated word cloud.\n",
        "    '''\n",
        "\n",
        "    # Filter the DataFrame by the specified cluster number and column name, removing NaN\n",
        "    df_wordcloud = netflix_df[['agglomerative_cluster', column_name]].dropna()\n",
        "    df_wordcloud = df_wordcloud[df_wordcloud['agglomerative_cluster'] == cluster_number]\n",
        "\n",
        "    # Combine all text documents into a single string\n",
        "    text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "    # Create the word cloud\n",
        "    wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"black\").generate(text)\n",
        "\n",
        "    # Return the WordCloud object representing the word cloud\n",
        "    return wordcloud\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots for plotting word clouds\n",
        "fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(20, 15))\n",
        "\n",
        "# Loop through clusters and attributes to generate and plot word clouds\n",
        "for i in range(2):\n",
        "    for j, col in enumerate(['description', 'listed_in', 'country', 'title']):\n",
        "        axs[j][i].imshow(agglomerative_wordcloud(i, col))\n",
        "        axs[j][i].axis('off')\n",
        "        axs[j][i].set_title(f'Cluster {i}, {col}', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Adjust the layout for better visualization\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "47dUmBcF4gH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Recommendaton System"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries for cosine similarity and TF-IDF vectorization\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create a TF-IDF vectorizer object and transform the text data\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(netflix_df['content_detail'])\n",
        "\n",
        "# Compute the cosine similarity matrix between all program descriptions\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "def recommend_content(title, cosine_sim=cosine_sim, data=netflix_df):\n",
        "    '''\n",
        "    Function to recommend content similar to a given title based on cosine similarity.\n",
        "\n",
        "    Args:\n",
        "        title (str): The title of the content for which recommendations are sought.\n",
        "        cosine_sim (array-like, optional): The cosine similarity matrix.\n",
        "        data (DataFrame, optional): The DataFrame containing the content data.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: A DataFrame containing the top 10 recommended titles and their similarity scores.\n",
        "    '''\n",
        "\n",
        "    # Get the index of the input title in the program list\n",
        "    programme_list = data['title'].to_list()\n",
        "    index = programme_list.index(title)\n",
        "\n",
        "    # Create a list of tuples containing the similarity score and index\n",
        "    # between the input title and all other programs in the dataset\n",
        "    sim_scores = list(enumerate(cosine_sim[index]))\n",
        "\n",
        "    # Sort the list of tuples by similarity score in descending order\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]\n",
        "\n",
        "    # Get the recommended movie titles and their similarity scores\n",
        "    recommend_index = [i[0] for i in sim_scores]\n",
        "    rec_movie = data['title'].iloc[recommend_index]\n",
        "    rec_score = [round(i[1], 4) for i in sim_scores]\n",
        "\n",
        "    # Create a pandas DataFrame to display the recommendations\n",
        "    rec_table = pd.DataFrame(list(zip(rec_movie, rec_score)), columns=['Recommendation', 'Similarity_score(0-1)'])\n",
        "\n",
        "    return rec_table\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, it's time to evaluate the performance of our recommender system."
      ],
      "metadata": {
        "id": "5-tw4g7a7qtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Indian movie\n",
        "indian_movie_recommendations = recommend_content('Zindagi Na Milegi Dobara')\n",
        "print(\"Recommendations for Indian Movie 'Zindagi Na Milegi Dobara':\")\n",
        "print(indian_movie_recommendations)\n",
        "\n",
        "# Testing non-Indian movie\n",
        "non_indian_movie_recommendations = recommend_content('THE RUM DIARY')\n",
        "print(\"\\nRecommendations for Non-Indian Movie 'THE RUM DIARY':\")\n",
        "print(non_indian_movie_recommendations)\n",
        "\n",
        "# Testing Indian TV show\n",
        "indian_tv_show_recommendations = recommend_content('Humsafar')\n",
        "print(\"\\nRecommendations for Indian TV Show 'Humsafar':\")\n",
        "print(indian_tv_show_recommendations)\n",
        "\n",
        "# Testing non-Indian TV show\n",
        "non_indian_tv_show_recommendations = recommend_content('The World Is Yours')\n",
        "print(\"\\nRecommendations for Non-Indian TV Show 'The World Is Yours':\")\n",
        "print(non_indian_tv_show_recommendations)\n"
      ],
      "metadata": {
        "id": "qRu-LiSv72xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've opted for the Silhouette Score as our evaluation metric for several reasons. The Silhouette Score measures how effectively each data point within a cluster is separated from other clusters. It operates on a scale from -1 to 1, with higher scores indicating better cluster separation. A score close to 1 suggests that a data point is well-suited to its own cluster and poorly suited to neighboring clusters. Conversely, a score near 0 implies a data point is at or very close to the boundary between two clusters, while a score close to -1 suggests the data point might be wrongly assigned.\n",
        "\n",
        "There are advantages to using the Silhouette Score over the Distortion Score (also known as inertia or sum of squared distances):\n",
        "\n",
        "1. The Silhouette Score takes both cohesion (similarity among data points within a cluster) and separation (dissimilarity between data points in different clusters) into account. In contrast, the Distortion Score only considers cluster compactness.\n",
        "\n",
        "2. Silhouette Score is less sensitive to cluster shape, making it suitable for clusters that are not perfectly spherical, which may be the case in our data.\n",
        "\n",
        "3. The Silhouette Score assigns a score to each data point, providing more detailed and interpretable results compared to the Distortion Score, which provides a single value for the entire clustering solution.\n",
        "\n",
        "This choice allows us to comprehensively assess the quality of our clustering results."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've chosen K-means as our final clustering model for several reasons:\n",
        "\n",
        "1. **High Silhouette Score:** K-means clustering has provided us with a comparatively high Silhouette Score, indicating that the clusters are well-separated and data points are appropriately assigned to clusters.\n",
        "\n",
        "2. **Effectiveness in Certain Situations:** K-means tends to perform well in situations where:\n",
        "\n",
        "   - **Speed**: It's faster than hierarchical clustering, making it advantageous for large datasets due to its simplicity and fewer computational requirements.\n",
        "   \n",
        "   - **Ease of Use**: K-means is straightforward to implement and interpret, with few parameters to tune, such as the number of clusters. It provides a clear partitioning of the data.\n",
        "   \n",
        "   - **Scalability**: K-means is scalable and can handle datasets with a large number of variables or dimensions, which is beneficial when dealing with high-dimensional data.\n",
        "   \n",
        "   - **Independence of Clusters**: K-means produces non-overlapping clusters, which can be preferable for applications where clear separation is needed.\n",
        "\n",
        "While K-means has its advantages, it's important to note that the choice of clustering algorithm should depend on the specific characteristics of your data and the goals of your analysis. Different algorithms may perform better in different scenarios, so it's essential to consider the nature of your data and your objectives when selecting a clustering method."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, both the exploratory data analysis (EDA) and the machine learning model have provided valuable insights into Netflix's content distribution, production trends, viewer preferences, and the effectiveness of clustering techniques for recommendation. Here are the key conclusions:\n",
        "\n",
        "**From EDA:**\n",
        "\n",
        "1. **Content Diversity and Global Reach:** Netflix's content library is diverse and caters to a global audience, emphasizing international TV shows and popular genres like crime and kids' TV.\n",
        "\n",
        "2. **Production Trends:** Netflix has experienced significant growth in content production, adapting to the evolving streaming landscape by creating more original content.\n",
        "\n",
        "3. **Global Influences:** The dominance of the United States and the rise of Indian content highlight regional and global factors shaping the industry.\n",
        "\n",
        "4. **Regional Success Stories:** South Korean dramas and Canadian financial support for TV shows have had a substantial impact on the platform.\n",
        "\n",
        "5. **Viewer Engagement:** Viewer preferences vary widely, with interests spanning Japanese voice actors, crime TV shows, kids' TV, British TV shows, and documentaries.\n",
        "\n",
        "6. **Quality and Collaboration:** Netflix collaborates with prolific directors and actors, emphasizing quality and collaboration within and beyond traditional entertainment.\n",
        "\n",
        "In essence, Netflix aims to serve a global audience with diverse, high-quality content, adapt to production trends, and engage viewers across cultures and genres.\n",
        "\n",
        "**From ML Model:**\n",
        "\n",
        "1. **Clustering Results:** K-Means clustering suggests an optimal number of 4 clusters, while Agglomerative Hierarchical Clustering indicates 2 clusters as optimal.\n",
        "\n",
        "2. **Evaluation Metric Choice:** Silhouette Score was chosen over Distortion Score due to its interpretability and robustness to cluster shape.\n",
        "\n",
        "3. **Recommendation System:** A recommendation system was developed to enhance user experience and reduce subscriber churn. It provides personalized recommendations based on similarity scores.\n",
        "\n",
        "In conclusion, the combination of data exploration and machine learning techniques has provided Netflix with valuable insights into its content and clustering solutions for content recommendations, enabling the platform to stay competitive in the ever-evolving world of streaming entertainment."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}